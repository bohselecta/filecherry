var __defProp = Object.defineProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};

// src/database.ts
import { ResolveOnce as ResolveOnce7 } from "@adviser/cement";

// src/write-queue.ts
function writeQueue(worker, payload = Infinity, unbounded = false) {
  const queue = [];
  let isProcessing = false;
  async function process() {
    if (isProcessing || queue.length === 0) return;
    isProcessing = true;
    const tasksToProcess = queue.splice(0, payload);
    const updates = tasksToProcess.map((item) => item.task);
    if (unbounded) {
      const promises = updates.map(async (update, index2) => {
        try {
          const result = await worker([update]);
          tasksToProcess[index2].resolve(result);
        } catch (error) {
          tasksToProcess[index2].reject(error);
        }
      });
      await Promise.all(promises);
    } else {
      try {
        const result = await worker(updates);
        tasksToProcess.forEach((task) => task.resolve(result));
      } catch (error) {
        tasksToProcess.forEach((task) => task.reject(error));
      }
    }
    isProcessing = false;
    void process();
  }
  return {
    push(task) {
      return new Promise((resolve, reject) => {
        queue.push({ task, resolve, reject });
        void process();
      });
    }
  };
}

// src/crdt.ts
import { ResolveOnce as ResolveOnce6 } from "@adviser/cement";

// src/runtime/wait-pr-multiformats/block.ts
var block_exports = {};
__export(block_exports, {
  Block: () => Block,
  create: () => create,
  createUnsafe: () => createUnsafe,
  decode: () => decode,
  encode: () => encode
});
import { bytes as binary, CID } from "multiformats";
import { Block as mfBlock } from "multiformats/block";
var Block = mfBlock;
async function decode({
  bytes,
  codec: codec3,
  hasher: hasher7
}) {
  if (bytes == null) throw new Error('Missing required argument "bytes"');
  if (codec3 == null || hasher7 == null) throw new Error("Missing required argument: codec or hasher");
  const value = await Promise.resolve(codec3.decode(bytes));
  const hash = await hasher7.digest(bytes);
  const cid = CID.create(1, codec3.code, hash);
  return new mfBlock({ value, bytes, cid });
}
async function encode({
  value,
  codec: codec3,
  hasher: hasher7
}) {
  if (typeof value === "undefined") throw new Error('Missing required argument "value"');
  if (codec3 == null || hasher7 == null) throw new Error("Missing required argument: codec or hasher");
  const bytes = await Promise.resolve(codec3.encode(value));
  const hash = await hasher7.digest(bytes);
  const cid = CID.create(1, codec3.code, hash);
  return new mfBlock({ value, bytes, cid });
}
async function create({
  bytes,
  cid,
  hasher: hasher7,
  codec: codec3
}) {
  if (bytes == null) throw new Error('Missing required argument "bytes"');
  if (hasher7 == null) throw new Error('Missing required argument "hasher"');
  const value = await Promise.resolve(codec3.decode(bytes));
  const hash = await hasher7.digest(bytes);
  if (!binary.equals(cid.multihash.bytes, hash.bytes)) {
    throw new Error("CID hash does not match bytes");
  }
  return createUnsafe({
    bytes,
    cid,
    value,
    codec: codec3
  });
}
async function createUnsafe({
  bytes,
  cid,
  value: maybeValue,
  codec: codec3
}) {
  const value = await Promise.resolve(maybeValue !== void 0 ? maybeValue : codec3?.decode(bytes));
  if (value === void 0) throw new Error('Missing required argument, must either provide "value" or "codec"');
  return new Block({
    cid,
    bytes,
    value
  });
}

// src/crdt-helpers.ts
import { parse as parse3 } from "multiformats/link";
import { sha256 as hasher5 } from "multiformats/hashes/sha2";
import * as codec from "@fireproof/vendor/@ipld/dag-cbor";
import { put, get, entries, root } from "@fireproof/vendor/@web3-storage/pail/crdt";
import { EventFetcher, vis } from "@fireproof/vendor/@web3-storage/pail/clock";
import * as Batch from "@fireproof/vendor/@web3-storage/pail/crdt/batch";

// src/blockstore/index.ts
var blockstore_exports = {};
__export(blockstore_exports, {
  BaseBlockstore: () => BaseBlockstore,
  CarTransaction: () => CarTransaction,
  CompactionFetcher: () => CompactionFetcher,
  ConnectionBase: () => ConnectionBase,
  EncryptedBlockstore: () => EncryptedBlockstore,
  FragmentGateway: () => FragmentGateway,
  Loader: () => Loader,
  addCryptoKeyToGatewayMetaPayload: () => addCryptoKeyToGatewayMetaPayload,
  ensureStart: () => ensureStart,
  getGatewayFromURL: () => getGatewayFromURL,
  parseCarFile: () => parseCarFile,
  registerStoreProtocol: () => registerStoreProtocol,
  setCryptoKeyFromGatewayMetaPayload: () => setCryptoKeyFromGatewayMetaPayload,
  testStoreFactory: () => testStoreFactory,
  toCIDBlock: () => toCIDBlock,
  toStoreRuntime: () => toStoreRuntime
});

// src/blockstore/types.ts
function toCIDBlock(block) {
  return block;
}

// src/blockstore/store-factory.ts
import { KeyedResolvOnce as KeyedResolvOnce2, URI as URI6, runtimeFn as runtimeFn3 } from "@adviser/cement";

// src/runtime/files.ts
var files_exports = {};
__export(files_exports, {
  decodeFile: () => decodeFile,
  encodeFile: () => encodeFile
});
import * as UnixFS from "@ipld/unixfs";
import * as raw from "multiformats/codecs/raw";
import { withMaxChunkSize } from "@ipld/unixfs/file/chunker/fixed";
import { withWidth } from "@ipld/unixfs/file/layout/balanced";
import { exporter } from "@fireproof/vendor/ipfs-unixfs-exporter";
var queuingStrategy = UnixFS.withCapacity();
var settings = UnixFS.configure({
  fileChunkEncoder: raw,
  smallFileEncoder: raw,
  chunker: withMaxChunkSize(1024 * 1024),
  fileLayout: withWidth(1024)
});
async function collect(collectable) {
  const chunks = [];
  await collectable.pipeTo(
    new WritableStream({
      write(chunk) {
        chunks.push(chunk);
      }
    })
  );
  return chunks;
}
async function encodeFile(blob) {
  const readable = createFileEncoderStream(blob);
  const blocks = await collect(readable);
  return { cid: blocks.at(-1).cid, blocks };
}
async function decodeFile(blocks, cid, meta) {
  const entry = await exporter(cid.toString(), blocks, { length: meta.size });
  const chunks = [];
  for await (const chunk of entry.content()) {
    chunks.push(chunk);
  }
  return new File(chunks, entry.name, { type: meta.type, lastModified: 0 });
}
function createFileEncoderStream(blob) {
  const { readable, writable } = new TransformStream({}, queuingStrategy);
  const unixfsWriter = UnixFS.createWriter({ writable, settings });
  const fileBuilder = new UnixFSFileBuilder("", blob);
  void (async () => {
    await fileBuilder.finalize(unixfsWriter);
    await unixfsWriter.close();
  })();
  return readable;
}
var UnixFSFileBuilder = class {
  #file;
  constructor(name, file) {
    this.name = name;
    this.#file = file;
  }
  async finalize(writer) {
    const unixfsFileWriter = UnixFS.createFileWriter(writer);
    await this.#file.stream().pipeTo(
      new WritableStream({
        async write(chunk) {
          await unixfsFileWriter.write(chunk);
        }
      })
    );
    return await unixfsFileWriter.close();
  }
};

// src/blockstore/store.ts
import { format as format2, parse as parse2 } from "@fireproof/vendor/@ipld/dag-json";
import { exception2Result, ResolveOnce as ResolveOnce4, Result as Result5 } from "@adviser/cement";

// src/types.ts
function isFalsy(value) {
  return value === false && value === null && value === void 0;
}
function throwFalsy(value) {
  if (isFalsy(value)) {
    throw new Error("value is Falsy");
  }
  return value;
}
function falsyToUndef(value) {
  if (isFalsy(value)) {
    return void 0;
  }
  return value;
}

// src/utils.ts
import {
  LoggerImpl,
  IsLogger,
  Result,
  ResolveOnce,
  isURL,
  URI,
  runtimeFn,
  envFactory,
  toCryptoRuntime,
  JSONFormatter,
  YAMLFormatter
} from "@adviser/cement";
import { base58btc } from "multiformats/bases/base58";
var _globalLogger = new ResolveOnce();
function globalLogger() {
  return _globalLogger.once(() => new LoggerImpl());
}
var registerFP_DEBUG = new ResolveOnce();
var SuperThisImpl = class _SuperThisImpl {
  constructor(opts) {
    this.logger = opts.logger;
    this.env = opts.env;
    this.crypto = opts.crypto;
    this.pathOps = opts.pathOps;
    this.txt = opts.txt;
    this.ctx = { ...opts.ctx };
  }
  nextId(bytes = 6) {
    const bin = this.crypto.randomBytes(bytes);
    return {
      str: base58btc.encode(bin),
      bin
    };
  }
  timeOrderedNextId(now) {
    now = typeof now === "number" ? now : (/* @__PURE__ */ new Date()).getTime();
    const t = (281474976710656 + now).toString(16).replace(/^1/, "");
    const bin = this.crypto.randomBytes(10);
    bin[1] = bin[1] & 240 | (bin[1] | 8 && 11);
    const hex = Array.from(bin).map((i) => i.toString(16).padStart(2, "0")).join("");
    return {
      str: `${t.slice(0, 8)}-${t.slice(8)}-7${hex.slice(0, 3)}-${hex.slice(3, 7)}-${hex.slice(7, 19)}`
    };
  }
  start() {
    return Promise.resolve();
  }
  clone(override) {
    return new _SuperThisImpl({
      logger: override.logger || this.logger,
      env: envFactory(override.env) || this.env,
      crypto: override.crypto || this.crypto,
      pathOps: override.pathOps || this.pathOps,
      txt: override.txt || this.txt,
      ctx: { ...this.ctx, ...override.ctx }
    });
  }
};
function presetEnv() {
  const penv = new Map([
    // ["FP_DEBUG", "xxx"],
    // ["FP_ENV", "development"],
    ...Array.from(
      Object.entries(
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        globalThis[Symbol.for("FP_PRESET_ENV")] || {}
      )
    )
    // .map(([k, v]) => [k, v as string])
  ]);
  return penv;
}
var pathOpsImpl = class {
  join(...paths) {
    return paths.map((i) => i.replace(/\/+$/, "")).join("/");
  }
  dirname(path) {
    return path.split("/").slice(0, -1).join("/");
  }
  // homedir() {
  //     throw new Error("SysContainer:homedir is not available in seeded state");
  //   }
};
var pathOps = new pathOpsImpl();
var txtOps = {
  // eslint-disable-next-line no-restricted-globals
  encode: (input) => new TextEncoder().encode(input),
  // eslint-disable-next-line no-restricted-globals
  decode: (input) => new TextDecoder().decode(input)
};
var _onSuperThis = /* @__PURE__ */ new Map();
function onSuperThis(fn) {
  const key = `onSuperThis-${Math.random().toString(36).slice(2)}`;
  _onSuperThis.set(key, fn);
  return () => {
    _onSuperThis.delete(key);
  };
}
function ensureSuperThis(osthis) {
  const env = envFactory({
    symbol: osthis?.env?.symbol || "FP_ENV",
    presetEnv: osthis?.env?.presetEnv || presetEnv()
  });
  const ret = new SuperThisImpl({
    logger: osthis?.logger || globalLogger(),
    env,
    crypto: osthis?.crypto || toCryptoRuntime(),
    ctx: osthis?.ctx || {},
    pathOps,
    txt: osthis?.txt || txtOps
  });
  _onSuperThis.forEach((fn) => fn(ret));
  return ret;
}
function ensureSuperLog(sthis, componentName, ctx) {
  return sthis.clone({
    logger: ensureLogger(sthis, componentName, ctx)
  });
}
function ensureLogger(sthis, componentName, ctx) {
  let logger;
  if (sthis && IsLogger(sthis.logger)) {
    logger = sthis.logger;
  } else {
    logger = globalLogger();
  }
  const cLogger = logger.With().Module(componentName);
  const debug = [];
  let exposeStack = false;
  if (ctx) {
    if ("debug" in ctx) {
      if (typeof ctx.debug === "string" && ctx.debug.length > 0) {
        debug.push(ctx.debug);
      } else {
        debug.push(componentName);
      }
      delete ctx.debug;
    }
    if ("exposeStack" in ctx) {
      exposeStack = true;
      delete ctx.exposeStack;
    }
    if ("this" in ctx) {
      cLogger.Str("this", sthis.nextId(4).str);
      delete ctx.this;
    }
    for (const [key, value] of Object.entries(ctx)) {
      switch (typeof value) {
        case "string":
          cLogger.Str(key, value);
          break;
        case "number":
          cLogger.Uint64(key, value);
          break;
        default:
          if (value instanceof Date) {
            cLogger.Str(key, value.toISOString());
          } else if (isURL(value)) {
            cLogger.Str(key, value.toString());
          } else if (typeof value === "function") {
            cLogger.Ref(key, value);
          } else {
            cLogger.Any(key, value);
          }
          break;
      }
    }
  }
  registerFP_DEBUG.once(async () => {
    sthis.env.onSet(
      (key, value) => {
        switch (key) {
          case "FP_FORMAT": {
            switch (value) {
              case "jsonice":
                logger.SetFormatter(new JSONFormatter(logger.TxtEnDe(), 2));
                break;
              case "yaml":
                logger.SetFormatter(new YAMLFormatter(logger.TxtEnDe(), 2));
                break;
              case "json":
              default:
                logger.SetFormatter(new JSONFormatter(logger.TxtEnDe()));
                break;
            }
            break;
          }
          case "FP_DEBUG":
            logger.SetDebug(value || []);
            break;
          case "FP_STACK":
            logger.SetExposeStack(!!value);
            break;
        }
      },
      "FP_FORMAT",
      "FP_DEBUG",
      "FP_STACK"
    );
  }).finally(() => {
  });
  if (debug.length > 0) {
    logger.SetDebug(debug);
  }
  if (exposeStack) {
    logger.SetExposeStack(true);
  }
  const out = cLogger.Logger();
  return out;
}
function getStore(url, sthis, joiner) {
  const store = url.getParam("store");
  switch (store) {
    case "data":
    case "wal":
    case "meta":
      break;
    default:
      throw sthis.logger.Error().Url(url).Msg(`store not found`).AsError();
  }
  let name = store;
  if (url.hasParam("index")) {
    name = joiner(url.getParam("index") || "idx", name);
  }
  return { store, name };
}
function getKey(url, logger) {
  const result = url.getParam("key");
  if (!result) throw logger.Error().Str("url", url.toString()).Msg(`key not found`).AsError();
  return result;
}
function getName(sthis, url) {
  let result = url.getParam("name");
  if (!result) {
    result = sthis.pathOps.dirname(url.pathname);
    if (result.length === 0) {
      throw sthis.logger.Error().Str("url", url.toString()).Msg(`name not found`).AsError();
    }
  }
  return result;
}
async function exceptionWrapper(fn) {
  return fn().catch((e) => Result.Err(e));
}
var NotFoundError = class extends Error {
  constructor() {
    super(...arguments);
    this.code = "ENOENT";
  }
};
function isNotFoundError(e) {
  if (Result.Is(e)) {
    if (e.isOk()) return false;
    e = e.Err();
  }
  if (e.code === "ENOENT") return true;
  return false;
}
function dataDir(sthis, name, base) {
  if (!base) {
    if (!runtimeFn().isBrowser) {
      const home = sthis.env.get("HOME") || "./";
      base = sthis.env.get("FP_STORAGE_URL") || `file://${sthis.pathOps.join(home, ".fireproof")}`;
    } else {
      base = sthis.env.get("FP_STORAGE_URL") || `indexdb://fp`;
    }
  }
  return URI.from(base.toString()).build().setParam("name", name || "").URI();
}
function UInt8ArrayEqual(a, b) {
  if (a.length !== b.length) {
    return false;
  }
  for (let i = 0; i < a.length; i++) {
    if (a[i] !== b[i]) {
      return false;
    }
  }
  return true;
}

// src/blockstore/loader.ts
import pLimit from "p-limit";
import { CarReader } from "@fireproof/vendor/@ipld/car/reader";
import { ResolveOnce as ResolveOnce3 } from "@adviser/cement";

// src/blockstore/loader-helpers.ts
import { sha256 as hasher } from "multiformats/hashes/sha2";
import * as dagCodec from "@fireproof/vendor/@ipld/dag-cbor";
async function parseCarFile(reader, logger) {
  const roots = await reader.getRoots();
  const header = await reader.get(roots[0]);
  if (!header) throw logger.Error().Msg("missing header block").AsError();
  const dec = await decode({ bytes: header.bytes, hasher, codec: dagCodec });
  const fpvalue = dec.value;
  if (fpvalue && !fpvalue.fp) {
    throw logger.Error().Msg("missing fp").AsError();
  }
  return fpvalue.fp;
}

// src/blockstore/transaction.ts
import { MemoryBlockstore } from "@fireproof/vendor/@web3-storage/pail/block";
import { toCryptoRuntime as toCryptoRuntime2 } from "@adviser/cement";
var CarTransaction = class extends MemoryBlockstore {
  constructor(parent, opts = { add: true, noLoader: false }) {
    super();
    if (opts.add) {
      parent.transactions.add(this);
    }
    this.parent = parent;
  }
  async get(cid) {
    return await this.superGet(cid) || falsyToUndef(await this.parent.get(cid));
  }
  async superGet(cid) {
    return super.get(cid);
  }
};
function defaultedBlockstoreRuntime(sthis, opts, component, ctx) {
  const logger = ensureLogger(sthis, component, ctx);
  const store = opts.store || {};
  return {
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    applyMeta: (meta, snap) => {
      return Promise.resolve();
    },
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    compact: async (blocks) => {
      return {};
    },
    autoCompact: 100,
    public: false,
    name: void 0,
    threshold: 1e3 * 1e3,
    ...opts,
    logger,
    keyBag: opts.keyBag || {},
    crypto: toCryptoRuntime2(opts.crypto),
    store,
    storeRuntime: toStoreRuntime(store, sthis)
  };
}
function blockstoreFactory(sthis, opts) {
  if (opts.name) {
    return new EncryptedBlockstore(sthis, opts);
  } else {
    return new BaseBlockstore(opts);
  }
}
var BaseBlockstore = class {
  constructor(ebOpts = {}) {
    this.transactions = /* @__PURE__ */ new Set();
    this.sthis = ensureSuperThis(ebOpts);
    this.ebOpts = defaultedBlockstoreRuntime(this.sthis, ebOpts, "BaseBlockstore");
    this.logger = this.ebOpts.logger;
  }
  // ready: Promise<void>;
  ready() {
    return Promise.resolve();
  }
  async close() {
  }
  async destroy() {
  }
  async compact() {
  }
  async get(cid) {
    if (!cid) throw this.logger.Error().Msg("required cid").AsError();
    for (const f of this.transactions) {
      const v = await f.superGet(cid);
      if (v) return v;
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  async put(cid, block) {
    throw this.logger.Error().Msg("use a transaction to put").AsError();
  }
  // TransactionMeta
  async transaction(fn, _opts) {
    const t = new CarTransaction(this, _opts);
    const done = await fn(t);
    this.lastTxMeta = done;
    return { t, meta: done };
  }
  openTransaction(opts = { add: true, noLoader: false }) {
    return new CarTransaction(this, opts);
  }
  async commitTransaction(t, done, opts) {
    if (!this.loader) throw this.logger.Error().Msg("loader required to commit").AsError();
    const cars = await this.loader?.commit(t, done, opts);
    if (this.ebOpts.autoCompact && this.loader.carLog.length > this.ebOpts.autoCompact) {
      setTimeout(() => void this.compact(), 10);
    }
    if (cars) {
      this.transactions.delete(t);
      return { meta: done, cars, t };
    }
    throw this.logger.Error().Msg("failed to commit car files").AsError();
  }
  async *entries() {
    const seen = /* @__PURE__ */ new Set();
    for (const t of this.transactions) {
      for await (const blk of t.entries()) {
        if (seen.has(blk.cid.toString())) continue;
        seen.add(blk.cid.toString());
        yield blk;
      }
    }
  }
};
var EncryptedBlockstore = class extends BaseBlockstore {
  constructor(sthis, ebOpts) {
    super(ebOpts);
    this.compacting = false;
    this.logger = ensureLogger(this.sthis, "EncryptedBlockstore");
    const { name } = ebOpts;
    if (!name) {
      throw this.logger.Error().Msg("name required").AsError();
    }
    this.name = name;
    this.loader = new Loader(this.name, ebOpts, sthis);
  }
  ready() {
    return this.loader.ready();
  }
  close() {
    return this.loader.close();
  }
  destroy() {
    return this.loader.destroy();
  }
  async get(cid) {
    const got = await super.get(cid);
    if (got) return got;
    if (!this.loader) {
      return;
    }
    return falsyToUndef(await this.loader.getBlock(cid));
  }
  async transaction(fn, opts = { noLoader: false }) {
    const { t, meta: done } = await super.transaction(fn);
    const cars = await this.loader.commit(t, done, opts);
    if (this.ebOpts.autoCompact && this.loader.carLog.length > this.ebOpts.autoCompact) {
      setTimeout(() => void this.compact(), 10);
    }
    if (cars) {
      this.transactions.delete(t);
      return { meta: done, cars, t };
    }
    throw this.logger.Error().Msg("failed to commit car files").AsError();
  }
  async getFile(car, cid) {
    await this.ready();
    if (!this.loader) throw this.logger.Error().Msg("loader required to get file, database must be named").AsError();
    const reader = await this.loader.loadFileCar(
      car
      /*, isPublic */
    );
    const block = await reader.get(cid);
    if (!block) throw this.logger.Error().Str("cid", cid.toString()).Msg(`Missing block`).AsError();
    return block.bytes;
  }
  async compact() {
    await this.ready();
    if (!this.loader) throw this.logger.Error().Msg("loader required to compact").AsError();
    if (this.loader.carLog.length < 2) return;
    const compactFn = this.ebOpts.compact || ((blocks) => this.defaultCompact(blocks, this.logger));
    if (!compactFn || this.compacting) return;
    const blockLog = new CompactionFetcher(this);
    this.compacting = true;
    const meta = await compactFn(blockLog);
    await this.loader?.commit(blockLog.loggedBlocks, meta, {
      compact: true,
      noLoader: true
    });
    this.compacting = false;
  }
  async defaultCompact(blocks, logger) {
    if (!this.loader) {
      throw logger.Error().Msg("no loader").AsError();
    }
    if (!this.lastTxMeta) {
      throw logger.Error().Msg("no lastTxMeta").AsError();
    }
    for await (const blk of this.loader.entries(false)) {
      blocks.loggedBlocks.putSync(blk.cid, blk.bytes);
    }
    for (const t of this.transactions) {
      for await (const blk of t.entries()) {
        blocks.loggedBlocks.putSync(blk.cid, blk.bytes);
      }
    }
    return this.lastTxMeta;
  }
  async *entries() {
    for await (const blk of this.loader.entries()) {
      yield blk;
    }
  }
};
var CompactionFetcher = class {
  constructor(blocks) {
    this.blockstore = blocks;
    this.loggedBlocks = new CarTransaction(blocks);
  }
  async get(cid) {
    const block = await this.blockstore.get(cid);
    if (block) this.loggedBlocks.putSync(cid, block.bytes);
    return falsyToUndef(block);
  }
};

// src/blockstore/commit-queue.ts
import { Future } from "@adviser/cement";
var CommitQueue = class {
  constructor() {
    this.queue = [];
    this.processing = false;
    this._waitIdleItems = /* @__PURE__ */ new Set();
  }
  waitIdle() {
    if (this.queue.length === 0 && !this.processing) {
      return Promise.resolve();
    }
    const fn = new Future();
    this._waitIdleItems.add(fn);
    return fn.asPromise();
  }
  async enqueue(fn) {
    return new Promise((resolve, reject) => {
      const queueFn = async () => {
        try {
          resolve(await fn());
        } catch (e) {
          reject(e);
        } finally {
          this.processing = false;
          this.processNext();
        }
      };
      this.queue.push(queueFn);
      if (!this.processing) {
        this.processNext();
      }
    });
  }
  processNext() {
    if (this.queue.length > 0 && !this.processing) {
      this.processing = true;
      const queueFn = this.queue.shift();
      if (queueFn) {
        queueFn().finally(() => {
        });
      }
    }
    if (this.queue.length === 0 && !this.processing) {
      const toResolve = Array.from(this._waitIdleItems);
      this._waitIdleItems.clear();
      toResolve.map((fn) => fn.resolve());
    }
  }
};

// src/runtime/key-bag.ts
var key_bag_exports = {};
__export(key_bag_exports, {
  KeyBag: () => KeyBag,
  defaultKeyBagUrl: () => defaultKeyBagUrl,
  getKeyBag: () => getKeyBag,
  registerKeyBagProviderFactory: () => registerKeyBagProviderFactory
});
import {
  KeyedResolvOnce,
  ResolveOnce as ResolveOnce2,
  ResolveSeq,
  Result as Result2,
  runtimeFn as runtimeFn2,
  toCryptoRuntime as toCryptoRuntime3,
  URI as URI2
} from "@adviser/cement";
import { base58btc as base58btc2 } from "multiformats/bases/base58";
var KeyBag = class {
  constructor(rt) {
    this.rt = rt;
    this._warnOnce = new ResolveOnce2();
    this._seq = new ResolveSeq();
    this.logger = ensureLogger(rt.sthis, "KeyBag");
    this.logger.Debug().Msg("KeyBag created");
  }
  async subtleKey(key) {
    const extractable = this.rt.url.getParam("extractKey") === "_deprecated_internal_api";
    if (extractable) {
      this._warnOnce.once(
        () => this.logger.Warn().Msg("extractKey is enabled via _deprecated_internal_api --- handle keys safely!!!")
      );
    }
    return await this.rt.crypto.importKey(
      "raw",
      // raw or jwk
      base58btc2.decode(key),
      // hexStringToUint8Array(key), // raw data
      "AES-GCM",
      extractable,
      ["encrypt", "decrypt"]
    );
  }
  async ensureKeyFromUrl(url, keyFactory) {
    const storeKey = url.getParam("storekey");
    if (storeKey === "insecure") {
      return Result2.Ok(url);
    }
    if (!storeKey) {
      const keyName = `@${keyFactory()}@`;
      const ret = await this.getNamedKey(keyName);
      if (ret.isErr()) {
        return ret;
      }
      const urb = url.build().setParam("storekey", keyName);
      return Result2.Ok(urb.URI());
    }
    if (storeKey.startsWith("@") && storeKey.endsWith("@")) {
      const ret = await this.getNamedKey(storeKey);
      if (ret.isErr()) {
        return ret;
      }
    }
    return Result2.Ok(url);
  }
  async toKeyWithFingerPrint(keyStr) {
    const material = base58btc2.decode(keyStr);
    const key = await this.subtleKey(keyStr);
    const fpr = await this.rt.crypto.digestSHA256(material);
    return Result2.Ok({
      key,
      fingerPrint: base58btc2.encode(new Uint8Array(fpr))
    });
  }
  async setNamedKey(name, key) {
    return this._seq.add(() => this._setNamedKey(name, key));
  }
  // avoid deadlock
  async _setNamedKey(name, key) {
    const item = {
      name,
      key
    };
    const bag = await this.rt.getBag();
    this.logger.Debug().Str("name", name).Msg("setNamedKey");
    await bag.set(name, item);
    return await this.toKeyWithFingerPrint(item.key);
  }
  async getNamedExtractableKey(name, failIfNotFound = false) {
    const ret = await this.getNamedKey(name, failIfNotFound);
    if (ret.isErr()) {
      return ret;
    }
    const named = ret.Ok();
    return Result2.Ok({
      ...named,
      extract: async () => {
        const ext = new Uint8Array(await this.rt.crypto.exportKey("raw", named.key));
        return {
          key: ext,
          keyStr: base58btc2.encode(ext)
        };
      }
    });
  }
  async getNamedKey(name, failIfNotFound = false) {
    const id = this.rt.sthis.nextId(4).str;
    return this._seq.add(async () => {
      const bag = await this.rt.getBag();
      const named = await bag.get(name);
      if (named) {
        const fpr = await this.toKeyWithFingerPrint(named.key);
        this.logger.Debug().Str("id", id).Str("name", name).Result("fpr", fpr).Msg("fingerPrint getNamedKey");
        return fpr;
      }
      if (failIfNotFound) {
        this.logger.Debug().Str("id", id).Str("name", name).Msg("failIfNotFound getNamedKey");
        return Result2.Err(new Error(`Key not found: ${name}`));
      }
      const ret = await this._setNamedKey(name, base58btc2.encode(this.rt.crypto.randomBytes(this.rt.keyLength)));
      this.logger.Debug().Str("id", id).Str("name", name).Result("fpr", ret).Msg("createKey getNamedKey-post");
      return ret;
    });
  }
};
var keyBagProviderFactories = new Map(
  [
    {
      protocol: "file:",
      factory: async (url, sthis) => {
        const { KeyBagProviderImpl } = await import("@fireproof/core/node");
        return new KeyBagProviderImpl(url, sthis);
      }
    },
    {
      protocol: "indexdb:",
      factory: async (url, sthis) => {
        const { KeyBagProviderImpl } = await import("@fireproof/core/web");
        return new KeyBagProviderImpl(url, sthis);
      }
    }
  ].map((i) => [i.protocol, i])
);
function registerKeyBagProviderFactory(item) {
  const protocol = item.protocol.endsWith(":") ? item.protocol : item.protocol + ":";
  keyBagProviderFactories.set(protocol, {
    ...item,
    protocol
  });
}
function defaultKeyBagUrl(sthis) {
  let bagFnameOrUrl = sthis.env.get("FP_KEYBAG_URL");
  let url;
  if (runtimeFn2().isBrowser) {
    url = URI2.from(bagFnameOrUrl || "indexdb://fp-keybag");
  } else {
    if (!bagFnameOrUrl) {
      const home = sthis.env.get("HOME");
      bagFnameOrUrl = `${home}/.fireproof/keybag`;
      url = URI2.from(`file://${bagFnameOrUrl}`);
    } else {
      url = URI2.from(bagFnameOrUrl);
    }
  }
  const logger = ensureLogger(sthis, "defaultKeyBagUrl");
  logger.Debug().Url(url).Msg("from env");
  return url;
}
function defaultKeyBagOpts(sthis, kbo) {
  if (kbo.keyRuntime) {
    return kbo.keyRuntime;
  }
  const logger = ensureLogger(sthis, "KeyBag");
  let url;
  if (kbo.url) {
    url = URI2.from(kbo.url);
    logger.Debug().Url(url).Msg("from opts");
  } else {
    url = defaultKeyBagUrl(sthis);
  }
  const kitem = keyBagProviderFactories.get(url.protocol);
  if (!kitem) {
    throw logger.Error().Url(url).Msg("unsupported protocol").AsError();
  }
  const getBag = async () => kitem.factory(url, sthis);
  if (url.hasParam("masterkey")) {
    throw logger.Error().Url(url).Msg("masterkey is not supported").AsError();
  }
  return {
    url,
    crypto: kbo.crypto || toCryptoRuntime3({}),
    sthis,
    logger,
    keyLength: kbo.keyLength || 16,
    getBag,
    id: () => {
      return url.toString();
    }
  };
}
var _keyBags = new KeyedResolvOnce();
async function getKeyBag(sthis, kbo = {}) {
  await sthis.start();
  const rt = defaultKeyBagOpts(sthis, kbo);
  return _keyBags.get(rt.id()).once(async () => new KeyBag(rt));
}

// src/blockstore/commitor.ts
import * as CBW from "@fireproof/vendor/@ipld/car/buffer-writer";
import { sha256 as hasher2 } from "multiformats/hashes/sha2";
import * as dagCodec2 from "@fireproof/vendor/@ipld/dag-cbor";
async function encodeCarFile(roots, t, codec3) {
  let size = 0;
  const headerSize = CBW.headerLength({ roots });
  size += headerSize;
  for (const { cid, bytes } of t.entries()) {
    size += CBW.blockLength({ cid, bytes });
  }
  const buffer = new Uint8Array(size);
  const writer = CBW.createWriter(buffer, { headerSize });
  for (const r of roots) {
    writer.addRoot(r);
  }
  for (const { cid, bytes } of t.entries()) {
    writer.write({ cid, bytes });
  }
  writer.close();
  return await encode({ value: writer.bytes, hasher: hasher2, codec: codec3 });
}
async function createCarFile(encoder, cid, t) {
  return encodeCarFile([cid], t, encoder);
}
async function commitFiles(fileStore, walStore, t, done) {
  const { files: roots } = makeFileCarHeader(done);
  const cids = [];
  const codec3 = (await fileStore.keyedCrypto()).codec();
  const cars = await prepareCarFilesFiles(codec3, roots, t);
  for (const car of cars) {
    const { cid, bytes } = car;
    await fileStore.save({ cid, bytes });
    await walStore.enqueueFile(
      cid
      /*, !!opts.public*/
    );
    cids.push(cid);
  }
  return cids;
}
function makeFileCarHeader(result) {
  const files = [];
  for (const [, meta] of Object.entries(result.files || {})) {
    if (meta && typeof meta === "object" && "cid" in meta && meta !== null) {
      files.push(meta.cid);
    }
  }
  return { ...result, files };
}
async function prepareCarFilesFiles(encoder, roots, t) {
  return [await encodeCarFile(roots, t, encoder)];
}
function makeCarHeader(meta, cars, compact = false) {
  const coreHeader = compact ? { cars: [], compact: cars } : { cars, compact: [] };
  return { ...coreHeader, meta };
}
async function encodeCarHeader(fp) {
  return await encode({
    value: { fp },
    hasher: hasher2,
    codec: dagCodec2
  });
}
async function commit(params, t, done, opts = { noLoader: false, compact: false }) {
  const fp = makeCarHeader(done, params.carLog, !!opts.compact);
  const rootBlock = await encodeCarHeader(fp);
  const cars = await prepareCarFiles(params.encoder, params.threshold, rootBlock, t);
  const cids = [];
  for (const car of cars) {
    const { cid, bytes } = car;
    await params.carStore.save({ cid, bytes });
    cids.push(cid);
  }
  const newDbMeta = { cars: cids };
  await params.WALStore.enqueue(newDbMeta, opts);
  await params.metaStore.save(newDbMeta);
  return { cgrp: cids, header: fp };
}
async function prepareCarFiles(encoder, threshold, rootBlock, t) {
  const carFiles = [];
  threshold = threshold || 128e3 * 8;
  let clonedt = new CarTransaction(t.parent, { add: false, noLoader: false });
  clonedt.putSync(rootBlock.cid, rootBlock.bytes);
  let newsize = CBW.blockLength(toCIDBlock(rootBlock));
  let cidRootBlock = rootBlock;
  for (const { cid, bytes } of t.entries()) {
    newsize += CBW.blockLength(toCIDBlock({ cid, bytes }));
    if (newsize >= threshold) {
      carFiles.push(await createCarFile(encoder, cidRootBlock.cid, clonedt));
      clonedt = new CarTransaction(t.parent, { add: false, noLoader: false });
      clonedt.putSync(cid, bytes);
      cidRootBlock = { cid, bytes };
      newsize = CBW.blockLength(toCIDBlock({ cid, bytes }));
    } else {
      clonedt.putSync(cid, bytes);
    }
  }
  carFiles.push(await createCarFile(encoder, cidRootBlock.cid, clonedt));
  return carFiles;
}

// src/blockstore/loader.ts
import { sha256 as hasher3 } from "multiformats/hashes/sha2";

// src/blockstore/task-manager.ts
var TaskManager = class {
  constructor(sthis, callback) {
    // we need to remove the events after some time
    this.eventsWeHandled = /* @__PURE__ */ new Set();
    this.queue = [];
    this.isProcessing = false;
    this.logger = ensureLogger(sthis, "TaskManager");
    this.callback = callback;
  }
  async handleEvent(cid, parents, dbMeta) {
    for (const parent of parents) {
      this.eventsWeHandled.add(parent.toString());
    }
    this.queue.push({ cid: cid.toString(), dbMeta, retries: 0 });
    this.queue = this.queue.filter(({ cid: cid2 }) => !this.eventsWeHandled.has(cid2));
    void this.processQueue();
  }
  async processQueue() {
    if (this.isProcessing) return;
    this.isProcessing = true;
    const filteredQueue = this.queue.filter(({ cid }) => !this.eventsWeHandled.has(cid));
    const first = filteredQueue[0];
    if (!first) {
      this.isProcessing = false;
      return;
    }
    try {
      await this.callback(first.dbMeta);
      this.eventsWeHandled.add(first.cid);
      this.queue = this.queue.filter(({ cid }) => !this.eventsWeHandled.has(cid));
    } catch (err) {
      if (first.retries++ > 3) {
        this.logger.Error().Str("cid", first.cid).Msg("failed to process event block after 3 retries");
        this.queue = this.queue.filter(({ cid }) => cid !== first.cid);
      }
      await new Promise((resolve) => setTimeout(resolve, 50));
      throw this.logger.Error().Err(err).Msg("failed to process event block").AsError();
    } finally {
      this.isProcessing = false;
      if (this.queue.length > 0) {
        void this.processQueue();
      }
    }
  }
};

// src/blockstore/loader.ts
function carLogIncludesGroup(list, cids) {
  return list.some((arr) => {
    return arr.toString() === cids.toString();
  });
}
function uniqueCids(list, remove = /* @__PURE__ */ new Set()) {
  const byString = /* @__PURE__ */ new Map();
  for (const cid of list) {
    if (remove.has(cid.toString())) continue;
    byString.set(cid.toString(), cid);
  }
  return [...byString.values()];
}
var Loader = class {
  constructor(name, ebOpts, sthis) {
    this.commitQueue = new CommitQueue();
    this.isCompacting = false;
    this.carReaders = /* @__PURE__ */ new Map();
    this.seenCompacted = /* @__PURE__ */ new Set();
    this.processedCars = /* @__PURE__ */ new Set();
    this.carLog = [];
    this.getBlockCache = /* @__PURE__ */ new Map();
    this.seenMeta = /* @__PURE__ */ new Set();
    this.writeLimit = pLimit(1);
    this.onceReady = new ResolveOnce3();
    this.name = name;
    this.sthis = sthis;
    this.ebOpts = defaultedBlockstoreRuntime(
      sthis,
      {
        ...ebOpts,
        name
      },
      "Loader"
    );
    this.logger = this.ebOpts.logger;
    this.taskManager = new TaskManager(sthis, async (dbMeta) => {
      await this.handleDbMetasFromStore([dbMeta]);
    });
  }
  // readonly id = uuidv4();
  async keyBag() {
    return getKeyBag(this.sthis, this.ebOpts.keyBag);
  }
  async carStore() {
    return this.ebOpts.storeRuntime.makeDataStore(this);
  }
  async fileStore() {
    return this.ebOpts.storeRuntime.makeDataStore(this);
  }
  async WALStore() {
    return this.ebOpts.storeRuntime.makeWALStore(this);
  }
  async metaStore() {
    return this.ebOpts.storeRuntime.makeMetaStore(this);
  }
  async ready() {
    return this.onceReady.once(async () => {
      const metas = await (await this.metaStore()).load();
      if (this.ebOpts.meta) {
        await this.handleDbMetasFromStore([this.ebOpts.meta]);
      } else if (metas) {
        await this.handleDbMetasFromStore(metas);
      }
    });
  }
  async close() {
    const toClose = await Promise.all([this.carStore(), this.metaStore(), this.fileStore(), this.WALStore()]);
    await Promise.all(toClose.map((store) => store.close()));
  }
  async destroy() {
    const toDestroy = await Promise.all([this.carStore(), this.metaStore(), this.fileStore(), this.WALStore()]);
    await Promise.all(toDestroy.map((store) => store.destroy()));
  }
  // async snapToCar(carCid: AnyLink | string) {
  //   await this.ready
  //   if (typeof carCid === 'string') {
  //     carCid = CID.parse(carCid)
  //   }
  //   const carHeader = await this.loadCarHeaderFromMeta({ car: carCid, key: this.key || null })
  //   this.carLog = [carCid, ...carHeader.cars]
  //   await this.getMoreReaders(carHeader.cars)
  //   await this._applyCarHeader(carHeader, true)
  // }
  async handleDbMetasFromStore(metas) {
    this.logger.Debug().Any("metas", metas).Msg("handleDbMetasFromStore");
    for (const meta of metas) {
      await this.writeLimit(async () => {
        await this.mergeDbMetaIntoClock(meta);
      });
    }
  }
  async mergeDbMetaIntoClock(meta) {
    if (this.isCompacting) {
      throw this.logger.Error().Msg("cannot merge while compacting").AsError();
    }
    if (this.seenMeta.has(meta.cars.toString())) return;
    this.seenMeta.add(meta.cars.toString());
    if (carLogIncludesGroup(this.carLog, meta.cars)) {
      return;
    }
    const carHeader = await this.loadCarHeaderFromMeta(meta);
    carHeader.compact.map((c) => c.toString()).forEach(this.seenCompacted.add, this.seenCompacted);
    await this.getMoreReaders(carHeader.cars.flat());
    this.carLog = [...uniqueCids([meta.cars, ...this.carLog, ...carHeader.cars], this.seenCompacted)];
    await this.ebOpts.applyMeta?.(carHeader.meta);
  }
  // protected async ingestKeyFromMeta(meta: DbMeta): Promise<void> {
  //   const { key } = meta;
  //   if (key) {
  //     await this.setKey(key);
  //   }
  // }
  async loadCarHeaderFromMeta({ cars: cids }) {
    const reader = await this.loadCar(cids[0]);
    return await parseCarFile(reader, this.logger);
  }
  // async _getKey(): Promise<string | undefined> {
  //   if (this.key) return this.key;
  //   // generate a random key
  //   if (!this.ebOpts.public) {
  //     await this.setKey(toHexString(this.ebOpts.crypto.randomBytes(32)));
  //   }
  //   return this.key || undefined;
  // }
  async commitFiles(t, done) {
    await this.ready();
    const fstore = await this.fileStore();
    const wstore = await this.WALStore();
    return this.commitQueue.enqueue(() => commitFiles(fstore, wstore, t, done));
  }
  async loadFileCar(cid) {
    return await this.storesLoadCar(cid, await this.fileStore(), this.remoteFileStore);
  }
  async commit(t, done, opts = { noLoader: false, compact: false }) {
    await this.ready();
    const fstore = await this.fileStore();
    const params = {
      encoder: (await fstore.keyedCrypto()).codec(),
      carLog: this.carLog,
      carStore: fstore,
      WALStore: await this.WALStore(),
      metaStore: await this.metaStore(),
      threshold: this.ebOpts.threshold
    };
    return this.commitQueue.enqueue(async () => {
      await this.cacheTransaction(t);
      const ret = await commit(params, t, done, opts);
      await this.updateCarLog(ret.cgrp, ret.header, !!opts.compact);
      return ret.cgrp;
    });
  }
  async updateCarLog(cids, fp, compact) {
    if (compact) {
      const previousCompactCid = fp.compact[fp.compact.length - 1];
      fp.compact.map((c) => c.toString()).forEach(this.seenCompacted.add, this.seenCompacted);
      this.carLog = [...uniqueCids([...this.carLog, ...fp.cars, cids], this.seenCompacted)];
      await this.removeCidsForCompact(previousCompactCid[0]).catch((e) => e);
    } else {
      this.carLog.unshift(cids);
    }
  }
  async cacheTransaction(t) {
    for await (const block of t.entries()) {
      const sBlock = block.cid.toString();
      if (!this.getBlockCache.has(sBlock)) {
        this.getBlockCache.set(sBlock, block);
      }
    }
  }
  async cacheCarReader(carCidStr, reader) {
    if (this.processedCars.has(carCidStr)) return;
    this.processedCars.add(carCidStr);
    for await (const block of reader.blocks()) {
      const sBlock = block.cid.toString();
      if (!this.getBlockCache.has(sBlock)) {
        this.getBlockCache.set(sBlock, block);
      }
    }
  }
  async removeCidsForCompact(cid) {
    const carHeader = await this.loadCarHeaderFromMeta({
      cars: [cid]
    });
    for (const cids of carHeader.compact) {
      for (const cid2 of cids) {
        await (await this.carStore()).remove(cid2);
      }
    }
  }
  // async flushCars() {
  //   await this.ready
  //   // for each cid in car log, make a dbMeta
  //   for (const cid of this.carLog) {
  //     const dbMeta = { car: cid, key: this.key || null } as DbMeta
  //     await this.remoteWAL!.enqueue(dbMeta, { public: false })
  //   }
  // }
  async *entries(cache2 = true) {
    await this.ready();
    if (cache2) {
      for (const [, block] of this.getBlockCache) {
        yield block;
      }
    } else {
      for (const [, block] of this.getBlockCache) {
        yield block;
      }
      for (const cids of this.carLog) {
        for (const cid of cids) {
          const reader = await this.loadCar(cid);
          if (!reader) throw this.logger.Error().Ref("cid", cid).Msg("missing car reader").AsError();
          for await (const block of reader.blocks()) {
            const sCid = block.cid.toString();
            if (!this.getBlockCache.has(sCid)) {
              yield block;
            }
          }
        }
      }
    }
  }
  async getBlock(cid) {
    await this.ready();
    const sCid = cid.toString();
    if (this.getBlockCache.has(sCid)) return this.getBlockCache.get(sCid);
    const getCarCid = async (carCid) => {
      if (this.getBlockCache.has(sCid)) return this.getBlockCache.get(sCid);
      const reader = await this.loadCar(carCid);
      if (!reader) {
        throw this.logger.Error().Ref("cid", carCid).Msg("missing car reader").AsError();
      }
      await this.cacheCarReader(carCid.toString(), reader).catch(() => {
        return;
      });
      if (this.getBlockCache.has(sCid)) return this.getBlockCache.get(sCid);
      throw this.logger.Error().Str("cid", sCid).Msg("block not in reader").AsError();
    };
    const getCompactCarCids = async (carCid) => {
      const reader = await this.loadCar(carCid);
      if (!reader) {
        throw this.logger.Error().Str("cid", carCid.toString()).Msg("missing car reader").AsError();
      }
      const header = await parseCarFile(reader, this.logger);
      const compacts = header.compact;
      let got2;
      const batchSize2 = 5;
      for (let i = 0; i < compacts.length; i += batchSize2) {
        const promises = [];
        for (let j = i; j < Math.min(i + batchSize2, compacts.length); j++) {
          for (const cid2 of compacts[j]) {
            promises.push(getCarCid(cid2));
          }
        }
        try {
          got2 = await Promise.any(promises);
        } catch {
        }
        if (got2) break;
      }
      if (this.getBlockCache.has(sCid)) return this.getBlockCache.get(sCid);
      throw this.logger.Error().Str("cid", sCid).Msg("block not in compact reader").AsError();
    };
    let got;
    const batchSize = 5;
    for (let i = 0; i < this.carLog.length; i += batchSize) {
      const batch = this.carLog.slice(i, i + batchSize);
      const promises = batch.flatMap((slice) => slice.map(getCarCid));
      try {
        got = await Promise.any(promises);
      } catch {
      }
      if (got) break;
    }
    if (!got) {
      try {
        got = await getCompactCarCids(this.carLog[this.carLog.length - 1][0]);
      } catch {
      }
    }
    return got;
  }
  async loadCar(cid) {
    if (!this.carStore) {
      throw this.logger.Error().Msg("car store not initialized").AsError();
    }
    const loaded = await this.storesLoadCar(cid, await this.carStore(), this.remoteCarStore);
    return loaded;
  }
  async makeDecoderAndCarReader(cid, local, remote) {
    const cidsString = cid.toString();
    let loadedCar = void 0;
    let activeStore = local;
    try {
      this.logger.Debug().Str("cid", cidsString).Msg("loading car");
      loadedCar = await local.load(cid);
      this.logger.Debug().Bool("loadedCar", loadedCar).Msg("loaded");
    } catch (e) {
      if (remote) {
        const remoteCar = await remote.load(cid);
        if (remoteCar) {
          this.logger.Debug().Ref("cid", remoteCar.cid).Msg("saving remote car locally");
          await local.save(remoteCar);
          loadedCar = remoteCar;
          activeStore = remote;
        }
      } else {
        this.logger.Error().Str("cid", cidsString).Err(e).Msg("loading car");
      }
    }
    if (!loadedCar) {
      throw this.logger.Error().Url(local.url()).Str("cid", cidsString).Msg("missing car files").AsError();
    }
    const bytes = await decode({ bytes: loadedCar.bytes, hasher: hasher3, codec: (await activeStore.keyedCrypto()).codec() });
    const rawReader = await CarReader.fromBytes(bytes.value);
    const readerP = Promise.resolve(rawReader);
    const cachedReaderP = readerP.then(async (reader) => {
      await this.cacheCarReader(cidsString, reader).catch((e) => {
        this.logger.Error().Err(e).Str("cid", cidsString).Msg("error caching car reader");
        return;
      });
      return reader;
    });
    this.carReaders.set(cidsString, cachedReaderP);
    return readerP;
  }
  //What if instead it returns an Array of CarHeader
  async storesLoadCar(cid, local, remote) {
    const cidsString = cid.toString();
    let dacr = this.carReaders.get(cidsString);
    if (!dacr) {
      dacr = this.makeDecoderAndCarReader(cid, local, remote);
      this.carReaders.set(cidsString, dacr);
    }
    return dacr;
  }
  async getMoreReaders(cids) {
    const limit = pLimit(5);
    const missing = cids.filter((cid) => !this.carReaders.has(cid.toString()));
    await Promise.all(missing.map((cid) => limit(() => this.loadCar(cid))));
  }
};

// src/runtime/keyed-crypto.ts
var keyed_crypto_exports = {};
__export(keyed_crypto_exports, {
  BlockIvKeyIdCodec: () => BlockIvKeyIdCodec,
  keyedCryptoFactory: () => keyedCryptoFactory
});
import { base58btc as base58btc3 } from "multiformats/bases/base58";
import { sha256 as hasher4 } from "multiformats/hashes/sha2";
import * as CBOR from "@fireproof/vendor/cborg";
var generateIV = {
  random: {
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    calc: async (ko, crypto, data) => {
      return crypto.randomBytes(ko.ivLength);
    },
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    verify: async (ko, crypto, iv, data) => {
      return true;
    }
  },
  hash: {
    calc: async (ko, crypto, data) => {
      const hash = await hasher4.digest(data);
      const hashBytes = new Uint8Array(hash.bytes);
      const hashArray = new Uint8Array(ko.ivLength);
      for (let i = 0; i < hashBytes.length; i++) {
        hashArray[i % ko.ivLength] ^= hashBytes[i];
      }
      return hashArray;
    },
    verify: async function(ko, crypto, iv, data) {
      return ko.url.getParam("ivverify") !== "disable" && UInt8ArrayEqual(iv, await this.calc(ko, crypto, data));
    }
  }
};
function getGenerateIVFn(url, opts) {
  const ivhash = opts.ivCalc || url.getParam("ivhash") || "hash";
  return generateIV[ivhash] || generateIV["hash"];
}
var BlockIvKeyIdCodec = class {
  constructor(ko, iv, opts) {
    this.code = 3147065;
    this.name = "Fireproof@encrypted-block:aes-gcm";
    this.ko = ko;
    this.iv = iv;
    this.opts = opts || {};
  }
  async encode(data) {
    const calcIv = this.iv || await getGenerateIVFn(this.ko.url, this.opts).calc(this.ko, this.ko.crypto, data);
    const { iv } = this.ko.algo(calcIv);
    const fprt = await this.ko.fingerPrint();
    const keyId = base58btc3.decode(fprt);
    this.ko.logger.Debug().Str("fp", fprt).Msg("encode");
    return CBOR.encode({
      iv,
      keyId,
      data: await this.ko._encrypt({ iv, bytes: data })
    });
  }
  async decode(abytes) {
    let bytes;
    if (abytes instanceof Uint8Array) {
      bytes = abytes;
    } else {
      bytes = new Uint8Array(abytes);
    }
    const { iv, keyId, data } = CBOR.decode(bytes);
    const fprt = await this.ko.fingerPrint();
    this.ko.logger.Debug().Str("fp", base58btc3.encode(keyId)).Msg("decode");
    if (base58btc3.encode(keyId) !== fprt) {
      throw this.ko.logger.Error().Str("fp", fprt).Str("keyId", base58btc3.encode(keyId)).Msg("keyId mismatch").AsError();
    }
    const result = await this.ko._decrypt({ iv, bytes: data });
    if (!this.opts?.noIVVerify && !await getGenerateIVFn(this.ko.url, this.opts).verify(this.ko, this.ko.crypto, iv, result)) {
      throw this.ko.logger.Error().Msg("iv missmatch").AsError();
    }
    return result;
  }
};
var keyedCrypto = class {
  constructor(url, key, cyopt, sthis) {
    this.ivLength = 12;
    this.isEncrypting = true;
    this.logger = ensureLogger(sthis, "keyedCrypto");
    this.crypto = cyopt;
    this.key = key;
    this.url = url;
  }
  fingerPrint() {
    return Promise.resolve(this.key.fingerPrint);
  }
  codec(iv, opts) {
    return new BlockIvKeyIdCodec(this, iv, opts);
  }
  algo(iv) {
    return {
      name: "AES-GCM",
      iv: iv || this.crypto.randomBytes(this.ivLength),
      tagLength: 128
    };
  }
  async _decrypt(data) {
    this.logger.Debug().Len(data.bytes, "bytes").Len(data.iv, "iv").Str("fp", this.key.fingerPrint).Msg("decrypting");
    return new Uint8Array(await this.crypto.decrypt(this.algo(data.iv), this.key.key, data.bytes));
  }
  async _encrypt(data) {
    this.logger.Debug().Len(data.bytes).Str("fp", this.key.fingerPrint).Msg("encrypting");
    const a = this.algo(data.iv);
    return new Uint8Array(await this.crypto.encrypt(a, this.key.key, data.bytes));
  }
};
var nullCodec = class {
  constructor() {
    this.code = 0;
    this.name = "Fireproof@unencrypted-block";
  }
  encode(data) {
    return data;
  }
  decode(data) {
    return data;
  }
};
var noCrypto = class {
  constructor(url, cyrt, sthis) {
    this.ivLength = 0;
    this.code = 0;
    this.name = "Fireproof@unencrypted-block";
    this.isEncrypting = false;
    this._fingerPrint = "noCrypto:" + Math.random();
    this.logger = ensureLogger(sthis, "noCrypto");
    this.crypto = cyrt;
    this.url = url;
  }
  fingerPrint() {
    return Promise.resolve(this._fingerPrint);
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  codec(iv) {
    return new nullCodec();
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  algo(iv) {
    return {
      name: "noCrypto",
      iv: new Uint8Array(),
      tagLength: 0
    };
  }
  _decrypt() {
    throw this.logger.Error().Msg("noCrypto.decrypt not implemented").AsError();
  }
  _encrypt() {
    throw this.logger.Error().Msg("noCrypto.decrypt not implemented").AsError();
  }
};
async function keyedCryptoFactory(url, kb, sthis) {
  const storekey = url.getParam("storekey");
  if (storekey && storekey !== "insecure") {
    let rkey = await kb.getNamedKey(storekey, true);
    if (rkey.isErr()) {
      try {
        rkey = await kb.toKeyWithFingerPrint(storekey);
      } catch (e) {
        throw sthis.logger.Error().Err(e).Str("keybag", kb.rt.id()).Str("name", storekey).Msg("getNamedKey failed").AsError();
      }
    }
    return new keyedCrypto(url, rkey.Ok(), kb.rt.crypto, sthis);
  }
  return new noCrypto(url, kb.rt.crypto, sthis);
}

// src/blockstore/fragment-gateway.ts
import { Result as Result3 } from "@adviser/cement";
import { base58btc as base58btc4 } from "multiformats/bases/base58";
import { encode as encode3, decode as decode3 } from "@fireproof/vendor/cborg";
function getFragSize(url) {
  const fragSize = url.getParam("fragSize");
  let ret = 0;
  if (fragSize) {
    ret = parseInt(fragSize);
  }
  if (isNaN(ret) || ret <= 0) {
    ret = 0;
  }
  return ret;
}
async function getFrags(url, innerGW, headerSize, logger) {
  const fragSize = getFragSize(url);
  if (!fragSize) {
    const res = await innerGW.get(url);
    if (res.isErr()) {
      return [res];
    }
    const data = res.unwrap();
    return [
      Result3.Ok({
        fid: new Uint8Array(0),
        ofs: 0,
        len: data.length,
        data
      })
    ];
  }
  const firstRaw = await innerGW.get(url.build().setParam("ofs", "0").URI());
  if (firstRaw.isErr()) {
    return [firstRaw];
  }
  const firstFragment = decode3(firstRaw.unwrap());
  const blockSize = firstFragment.data.length;
  const ops = [Promise.resolve(Result3.Ok(firstFragment))];
  const fidStr = base58btc4.encode(firstFragment.fid);
  const fragUrl = url.build().setParam("fid", fidStr).setParam("len", firstFragment.len.toString()).setParam("headerSize", headerSize.toString());
  for (let ofs = blockSize; ofs < firstFragment.len; ofs += blockSize) {
    ops.push(
      (async (furl, ofs2) => {
        const raw2 = await innerGW.get(furl);
        if (raw2.isErr()) {
          return raw2;
        }
        const fragment = decode3(raw2.unwrap());
        if (base58btc4.encode(fragment.fid) !== fidStr) {
          return Result3.Err(logger.Error().Msg("Fragment fid mismatch").AsError());
        }
        if (fragment.ofs !== ofs2) {
          return Result3.Err(logger.Error().Uint64("ofs", ofs2).Msg("Fragment ofs mismatch").AsError());
        }
        return Result3.Ok(fragment);
      })(fragUrl.setParam("ofs", ofs.toString()).URI(), ofs)
    );
  }
  return Promise.all(ops);
}
var FragmentGateway = class {
  constructor(sthis, innerGW) {
    this.fidLength = 4;
    this.headerSize = 32;
    this.sthis = ensureSuperLog(sthis, "FragmentGateway");
    this.logger = this.sthis.logger;
    this.innerGW = innerGW;
  }
  slicer(url, body) {
    const fragSize = getFragSize(url);
    if (!fragSize) {
      return [this.innerGW.put(url, body)];
    }
    const blocksize = fragSize - this.headerSize;
    if (blocksize <= 0) {
      throw this.logger.Error().Uint64("fragSize", fragSize).Uint64("headerSize", this.headerSize).Msg("Fragment size is too small").AsError();
    }
    const ops = [];
    const fid = this.sthis.nextId(this.fidLength);
    const fragUrl = url.build().setParam("fid", fid.str).setParam("len", body.length.toString()).setParam("headerSize", this.headerSize.toString());
    for (let ofs = 0; ofs < body.length; ofs += blocksize) {
      const block = encode3({
        fid: fid.bin,
        ofs,
        len: body.length,
        data: body.slice(ofs, ofs + blocksize)
      });
      if (block.length > fragSize) {
        throw this.logger.Error().Uint64("block", block.length).Uint64("fragSize", fragSize).Msg("Block size to big").AsError();
      }
      ops.push(this.innerGW.put(fragUrl.setParam("ofs", ofs.toString()).URI(), block));
    }
    return ops;
  }
  buildUrl(baseUrl, key) {
    return this.innerGW.buildUrl(baseUrl, key);
  }
  async destroy(iurl) {
    return this.innerGW.destroy(iurl);
  }
  async start(url) {
    this.headerSize = encode3({
      fid: this.sthis.nextId(this.fidLength).bin,
      ofs: 1024 * 1024,
      // 32bit
      len: 16 * 1024 * 1024,
      // 32bit
      data: new Uint8Array(1024)
    }).length - 1024;
    return this.innerGW.start(url);
  }
  async close(url) {
    return this.innerGW.close(url);
  }
  async put(url, body) {
    await Promise.all(this.slicer(url, body));
    return Result3.Ok(void 0);
  }
  async get(url) {
    const rfrags = await getFrags(url, this.innerGW, this.headerSize, this.logger);
    let buffer = void 0;
    for (const rfrag of rfrags) {
      if (rfrag.isErr()) {
        return Result3.Err(rfrag.Err());
      }
      const frag = rfrag.Ok();
      buffer = buffer || new Uint8Array(frag.len);
      buffer.set(frag.data, frag.ofs);
    }
    return Result3.Ok(buffer || new Uint8Array(0));
  }
  async subscribe(url, callback) {
    if (this.innerGW.subscribe) {
      return this.innerGW.subscribe(url, callback);
    } else {
      return Result3.Err(this.logger.Error().Url(url).Msg("subscribe not supported").AsError());
    }
  }
  async delete(url) {
    const rfrags = await getFrags(url, this.innerGW, this.headerSize, this.logger);
    for (const rfrag of rfrags) {
      if (rfrag.isErr()) {
        return Result3.Err(rfrag.Err());
      }
      const frag = rfrag.Ok();
      const fidStr = base58btc4.encode(frag.fid);
      const fragUrl = url.build().setParam("fid", fidStr).setParam("len", frag.len.toString()).setParam("headerSize", this.headerSize.toString()).URI();
      await this.innerGW.delete(fragUrl);
    }
    return Result3.Ok(void 0);
  }
};

// src/blockstore/meta-key-helper.ts
import { format, parse } from "@fireproof/vendor/@ipld/dag-json";
import { EventBlock, decodeEventBlock } from "@fireproof/vendor/@web3-storage/pail/clock";
import { CID as CID2 } from "multiformats";
import { base64pad } from "multiformats/bases/base64";
import { Result as Result4 } from "@adviser/cement";
async function decodeGatewayMetaBytesToDbMeta(sthis, byteHeads) {
  const crdtEntries = JSON.parse(sthis.txt.decode(byteHeads));
  if (!Array.isArray(crdtEntries)) {
    sthis.logger.Debug().Str("crdtEntries", JSON.stringify(crdtEntries)).Msg("No data in CRDT entries");
    return [];
  }
  if (!crdtEntries.length) {
    sthis.logger.Debug().Any("byteHeads", byteHeads).Msg("No CRDT entries found");
    return [];
  }
  const logger = ensureLogger(sthis, "decodeGatewayMetaBytesToDbMeta");
  return Promise.all(
    crdtEntries.map(async (crdtEntry) => {
      const eventBlock = await decodeEventBlock(base64pad.decode(crdtEntry.data));
      const dbMeta = parse(sthis.txt.decode(eventBlock.value.data.dbMeta));
      logger.Debug().Any("crdtEntry", {
        crdtEntry,
        eventBlock,
        dbMeta,
        dbMetaStrings: dbMeta.cars.map((car) => car.toString())
      }).Msg("CRDT entry");
      return {
        eventCid: eventBlock.cid,
        parents: crdtEntry.parents,
        dbMeta
      };
    })
  );
}
async function setCryptoKeyFromGatewayMetaPayload(uri, sthis, data) {
  try {
    sthis.logger.Debug().Str("uri", uri.toString()).Msg("Setting crypto key from gateway meta payload");
    const keyInfo = await decodeGatewayMetaBytesToDbMeta(sthis, data);
    if (keyInfo.length) {
      const dbMeta = keyInfo[0].dbMeta;
      if (dbMeta.key) {
        const kb = await getKeyBag(sthis);
        const keyName = getStoreKeyName(uri);
        const res = await kb.setNamedKey(keyName, dbMeta.key);
        if (res.isErr()) {
          sthis.logger.Debug().Str("keyName", keyName).Str("dbMeta.key", dbMeta.key).Msg("Failed to set named key");
          throw res.Err();
        }
      }
      sthis.logger.Debug().Str("dbMeta.key", dbMeta.key).Str("uri", uri.toString()).Msg("Set crypto key from gateway meta payload");
      return Result4.Ok(dbMeta);
    }
    sthis.logger.Debug().Any("data", data).Msg("No crypto in gateway meta payload");
    return Result4.Ok(void 0);
  } catch (error) {
    sthis.logger.Debug().Err(error).Msg("Failed to set crypto key from gateway meta payload");
    return Result4.Err(error);
  }
}
async function addCryptoKeyToGatewayMetaPayload(uri, sthis, body) {
  try {
    sthis.logger.Debug().Str("uri", uri.toString()).Msg("Adding crypto key to gateway meta payload");
    const keyName = getStoreKeyName(uri);
    const kb = await getKeyBag(sthis);
    const res = await kb.getNamedExtractableKey(keyName, true);
    if (res.isErr()) {
      sthis.logger.Error().Str("keyName", keyName).Msg("Failed to get named extractable key");
      throw res.Err();
    }
    const keyData = await res.Ok().extract();
    const dbMetas = await decodeGatewayMetaBytesToDbMeta(sthis, body);
    const { dbMeta, parents } = dbMetas[0];
    const parentLinks = parents.map((p) => CID2.parse(p));
    dbMeta.key = keyData.keyStr;
    const events = await Promise.all([dbMeta].map((dbMeta2) => createDbMetaEventBlock(sthis, dbMeta2, parentLinks)));
    const encoded = await encodeEventsWithParents(sthis, events, parentLinks);
    sthis.logger.Debug().Str("uri", uri.toString()).Msg("Added crypto key to gateway meta payload");
    return Result4.Ok(encoded);
  } catch (error) {
    sthis.logger.Error().Err(error).Msg("Failed to add crypto key to gateway meta payload");
    return Result4.Err(error);
  }
}
function getStoreKeyName(url) {
  const storeKeyName = [url.getParam("localName") || url.getParam("name")];
  const idx = url.getParam("index");
  if (idx) {
    storeKeyName.push(idx);
  }
  storeKeyName.push("data");
  return `@${storeKeyName.join(":")}@`;
}
async function createDbMetaEventBlock(sthis, dbMeta, parents) {
  const event = await EventBlock.create(
    {
      dbMeta: sthis.txt.encode(format(dbMeta))
    },
    parents
  );
  return event;
}
async function encodeEventsWithParents(sthis, events, parents) {
  const crdtEntries = events.map((event) => {
    const base64String = base64pad.encode(event.bytes);
    return {
      cid: event.cid.toString(),
      data: base64String,
      parents: parents.map((p) => p.toString())
    };
  });
  return sthis.txt.encode(JSON.stringify(crdtEntries));
}

// src/blockstore/store.ts
import pRetry from "p-retry";
import pMap from "p-map";
function guardVersion(url) {
  if (!url.hasParam("version")) {
    return Result5.Err(`missing version: ${url.toString()}`);
  }
  return Result5.Ok(url);
}
var BaseStoreImpl = class {
  constructor(name, url, opts, sthis, logger) {
    this._onStarted = [];
    this._onClosed = [];
    this.name = name;
    this._url = url;
    this.keybag = opts.keybag;
    this.sthis = sthis;
    this.logger = logger.With().Ref("url", () => this._url.toString()).Str("name", name).Logger();
    this.gateway = new FragmentGateway(this.sthis, opts.gateway);
    this.loader = opts.loader;
  }
  url() {
    return this._url;
  }
  onStarted(fn) {
    this._onStarted.push(fn);
  }
  onClosed(fn) {
    this._onClosed.push(fn);
  }
  async ready() {
    return;
  }
  async keyedCrypto() {
    return keyedCryptoFactory(this._url, await this.keybag(), this.sthis);
  }
  async start() {
    this.logger.Debug().Str("storeType", this.storeType).Msg("starting-gateway-pre");
    this._url = this._url.build().setParam("store", this.storeType).URI();
    const res = await this.gateway.start(this._url);
    if (res.isErr()) {
      this.logger.Error().Result("gw-start", res).Msg("started-gateway");
      return res;
    }
    this._url = res.Ok();
    const kb = await this.keybag();
    const skRes = await kb.ensureKeyFromUrl(this._url, () => {
      const idx = this._url.getParam("index");
      const storeKeyName = [this.name];
      if (idx) {
        storeKeyName.push(idx);
      }
      storeKeyName.push(this.storeType);
      return storeKeyName.join(":");
    });
    if (skRes.isErr()) {
      return skRes;
    }
    this._url = skRes.Ok();
    const version = guardVersion(this._url);
    if (version.isErr()) {
      this.logger.Error().Result("version", version).Msg("guardVersion");
      await this.close();
      return version;
    }
    if (this.ready) {
      const fn = this.ready.bind(this);
      const ready = await exception2Result(fn);
      if (ready.isErr()) {
        await this.close();
        return ready;
      }
    }
    this._onStarted.forEach((fn) => fn());
    this.logger.Debug().Msg("started");
    return version;
  }
};
var MetaStoreImpl = class extends BaseStoreImpl {
  // remote: boolean;
  constructor(sthis, name, url, opts) {
    super(name, url, { ...opts }, sthis, ensureLogger(sthis, "MetaStoreImpl"));
    this.storeType = "meta";
    this.subscribers = /* @__PURE__ */ new Map();
    this.parents = [];
    if (
      /*this.remote && */
      opts.gateway.subscribe
    ) {
      this.onStarted(async () => {
        this.logger.Debug().Str("url", this.url().toString()).Msg("Subscribing to the gateway");
        opts.gateway.subscribe?.(this.url(), async (message) => {
          this.logger.Debug().Msg("Received message from gateway");
          const dbMetas = await decodeGatewayMetaBytesToDbMeta(this.sthis, message);
          await Promise.all(
            dbMetas.map((dbMeta) => this.loader?.taskManager?.handleEvent(dbMeta.eventCid, dbMeta.parents, dbMeta.dbMeta))
          );
          this.updateParentsFromDbMetas(dbMetas);
        });
      });
    }
  }
  updateParentsFromDbMetas(dbMetas) {
    const cids = dbMetas.map((m) => m.eventCid);
    const dbMetaParents = dbMetas.flatMap((m) => m.parents);
    const uniqueParentsMap = new Map([...this.parents, ...cids].map((p) => [p.toString(), p]));
    const dbMetaParentsSet = new Set(dbMetaParents.map((p) => p.toString()));
    this.parents = Array.from(uniqueParentsMap.values()).filter((p) => !dbMetaParentsSet.has(p.toString()));
  }
  async handleByteHeads(byteHeads) {
    return await decodeGatewayMetaBytesToDbMeta(this.sthis, byteHeads);
  }
  async load() {
    const branch = "main";
    const url = await this.gateway.buildUrl(this.url(), branch);
    if (url.isErr()) {
      throw this.logger.Error().Result("buildUrl", url).Str("branch", branch).Msg("got error from gateway.buildUrl").AsError();
    }
    const bytes = await this.gateway.get(url.Ok());
    if (bytes.isErr()) {
      if (isNotFoundError(bytes)) {
        return void 0;
      }
      throw this.logger.Error().Url(url.Ok()).Result("bytes:", bytes).Msg("gateway get").AsError();
    }
    const dbMetas = await this.handleByteHeads(bytes.Ok());
    await this.loader?.handleDbMetasFromStore(dbMetas.map((m) => m.dbMeta));
    this.updateParentsFromDbMetas(dbMetas);
    return dbMetas.map((m) => m.dbMeta);
  }
  async save(meta, branch) {
    branch = branch || "main";
    this.logger.Debug().Str("branch", branch).Any("meta", meta).Msg("saving meta");
    const event = await createDbMetaEventBlock(this.sthis, meta, this.parents);
    const bytes = await encodeEventsWithParents(this.sthis, [event], this.parents);
    const url = await this.gateway.buildUrl(this.url(), branch);
    if (url.isErr()) {
      throw this.logger.Error().Err(url.Err()).Str("branch", branch).Msg("got error from gateway.buildUrl").AsError();
    }
    this.parents = [event.cid];
    const res = await this.gateway.put(url.Ok(), bytes);
    if (res.isErr()) {
      throw this.logger.Error().Err(res.Err()).Msg("got error from gateway.put").AsError();
    }
    return res;
  }
  async close() {
    await this.gateway.close(this.url());
    this._onClosed.forEach((fn) => fn());
    return Result5.Ok(void 0);
  }
  async destroy() {
    return this.gateway.destroy(this.url());
  }
};
var DataStoreImpl = class extends BaseStoreImpl {
  // readonly tag: string = "car-base";
  constructor(sthis, name, url, opts) {
    super(name, url, { ...opts }, sthis, ensureLogger(sthis, "DataStoreImpl"));
    this.storeType = "data";
  }
  async load(cid) {
    this.logger.Debug().Any("cid", cid).Msg("loading");
    const url = await this.gateway.buildUrl(this.url(), cid.toString());
    if (url.isErr()) {
      throw this.logger.Error().Err(url.Err()).Str("cid", cid.toString()).Msg("got error from gateway.buildUrl").AsError();
    }
    const res = await this.gateway.get(url.Ok());
    if (res.isErr()) {
      throw res.Err();
    }
    return { cid, bytes: res.Ok() };
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  async save(car, opts) {
    this.logger.Debug().Any("cid", car.cid.toString()).Msg("saving");
    const url = await this.gateway.buildUrl(this.url(), car.cid.toString());
    if (url.isErr()) {
      throw this.logger.Error().Err(url.Err()).Ref("cid", car.cid).Msg("got error from gateway.buildUrl").AsError();
    }
    const res = await this.gateway.put(url.Ok(), car.bytes);
    if (res.isErr()) {
      throw this.logger.Error().Err(res.Err()).Msg("got error from gateway.put").AsError();
    }
    return res.Ok();
  }
  async remove(cid) {
    const url = await this.gateway.buildUrl(this.url(), cid.toString());
    if (url.isErr()) {
      return url;
    }
    return this.gateway.delete(url.Ok());
  }
  async close() {
    await this.gateway.close(this.url());
    this._onClosed.forEach((fn) => fn());
    return Result5.Ok(void 0);
  }
  destroy() {
    return this.gateway.destroy(this.url());
  }
};
var WALStoreImpl = class extends BaseStoreImpl {
  constructor(loader, url, opts) {
    super(loader.name, url, { ...opts }, loader.sthis, ensureLogger(loader.sthis, "WALStoreImpl"));
    this.storeType = "wal";
    this._ready = new ResolveOnce4();
    this.walState = { operations: [], noLoaderOps: [], fileOperations: [] };
    this.processing = void 0;
    this.processQueue = new CommitQueue();
    this.loader = loader;
  }
  async ready() {
    return this._ready.once(async () => {
      const walState = await this.load().catch((e) => {
        this.logger.Error().Any("error", e).Msg("error loading wal");
        return void 0;
      });
      if (!walState) {
        this.walState.operations = [];
        this.walState.fileOperations = [];
      } else {
        this.walState.operations = walState.operations || [];
        this.walState.fileOperations = walState.fileOperations || [];
      }
    });
  }
  async enqueue(dbMeta, opts) {
    await this.ready();
    if (opts.compact) {
      this.walState.operations = [];
      this.walState.noLoaderOps = [dbMeta];
    } else if (opts.noLoader) {
      this.walState.noLoaderOps.push(dbMeta);
    } else {
      this.walState.operations.push(dbMeta);
    }
    await this.save(this.walState);
    if (!opts.noLoader) {
      void this.process();
    }
  }
  async enqueueFile(fileCid, publicFile = false) {
    await this.ready();
    this.walState.fileOperations.push({ cid: fileCid, public: publicFile });
  }
  async process() {
    await this.ready();
    if (!this.loader.remoteCarStore) return;
    await this.processQueue.enqueue(async () => {
      try {
        await this._doProcess();
      } catch (e) {
        this.logger.Error().Any("error", e).Msg("error processing wal");
      }
      if (this.walState.operations.length || this.walState.fileOperations.length || this.walState.noLoaderOps.length) {
        setTimeout(() => void this.process(), 0);
      }
    });
  }
  async _doProcess() {
    if (!this.loader.remoteCarStore) return;
    const operations = [...this.walState.operations];
    const noLoaderOps = [...this.walState.noLoaderOps];
    const fileOperations = [...this.walState.fileOperations];
    if (operations.length + noLoaderOps.length + fileOperations.length === 0) return;
    const concurrencyLimit = 3;
    const retryableUpload = (fn, description) => pRetry(fn, {
      retries: 5,
      onFailedAttempt: (error) => {
        this.logger.Warn().Msg(`Attempt ${error.attemptNumber} failed for ${description}. There are ${error.retriesLeft} retries left.`);
      }
    });
    try {
      await pMap(
        noLoaderOps,
        async (dbMeta) => {
          await retryableUpload(async () => {
            for (const cid of dbMeta.cars) {
              const car = await (await this.loader.carStore()).load(cid);
              if (!car) {
                if (carLogIncludesGroup(this.loader.carLog, dbMeta.cars)) {
                  throw this.logger.Error().Ref("cid", cid).Msg("missing local car").AsError();
                }
              } else {
                await throwFalsy(this.loader.remoteCarStore).save(car);
              }
            }
            this.walState.noLoaderOps = this.walState.noLoaderOps.filter((op) => op !== dbMeta);
          }, `noLoaderOp with dbMeta.cars=${dbMeta.cars.toString()}`);
        },
        { concurrency: concurrencyLimit }
      );
      await pMap(
        operations,
        async (dbMeta) => {
          await retryableUpload(async () => {
            for (const cid of dbMeta.cars) {
              const car = await (await this.loader.carStore()).load(cid);
              if (!car) {
                if (carLogIncludesGroup(this.loader.carLog, dbMeta.cars)) {
                  throw this.logger.Error().Ref("cid", cid).Msg(`missing local car`).AsError();
                }
              } else {
                await throwFalsy(this.loader.remoteCarStore).save(car);
              }
            }
            this.walState.operations = this.walState.operations.filter((op) => op !== dbMeta);
          }, `operation with dbMeta.cars=${dbMeta.cars.toString()}`);
        },
        { concurrency: concurrencyLimit }
      );
      await pMap(
        fileOperations,
        async ({ cid: fileCid, public: publicFile }) => {
          await retryableUpload(async () => {
            const fileBlock = await (await this.loader.fileStore()).load(fileCid);
            if (!fileBlock) {
              throw this.logger.Error().Ref("cid", fileCid).Msg("missing file block").AsError();
            }
            await this.loader.remoteFileStore?.save(fileBlock, { public: publicFile });
            this.walState.fileOperations = this.walState.fileOperations.filter((op) => op.cid !== fileCid);
          }, `fileOperation with cid=${fileCid.toString()}`);
        },
        { concurrency: concurrencyLimit }
      );
      if (operations.length) {
        const lastOp = operations[operations.length - 1];
        await retryableUpload(async () => {
          await this.loader.remoteMetaStore?.save(lastOp);
        }, `remoteMetaStore save with dbMeta.cars=${lastOp.cars.toString()}`);
      }
    } catch (error) {
      this.logger.Error().Any("error", error).Msg("Processing failed");
      return;
    } finally {
      await this.save(this.walState);
    }
  }
  async load() {
    this.logger.Debug().Msg("loading");
    const filepath = await this.gateway.buildUrl(this.url(), "main");
    if (filepath.isErr()) {
      throw this.logger.Error().Err(filepath.Err()).Url(this.url()).Msg("error building url").AsError();
    }
    const bytes = await this.gateway.get(filepath.Ok());
    if (bytes.isErr()) {
      if (isNotFoundError(bytes)) {
        return void 0;
      }
      throw this.logger.Error().Err(bytes.Err()).Msg("error get").AsError();
    }
    try {
      return bytes && parse2(this.sthis.txt.decode(bytes.Ok()));
    } catch (e) {
      throw this.logger.Error().Err(e).Msg("error parse").AsError();
    }
  }
  async save(state) {
    const filepath = await this.gateway.buildUrl(this.url(), "main");
    if (filepath.isErr()) {
      throw this.logger.Error().Err(filepath.Err()).Url(this.url()).Msg("error building url").AsError();
    }
    let encoded;
    try {
      encoded = format2(state);
    } catch (e) {
      throw this.logger.Error().Err(e).Any("state", state).Msg("error format").AsError();
    }
    const res = await this.gateway.put(filepath.Ok(), this.sthis.txt.encode(encoded));
    if (res.isErr()) {
      throw this.logger.Error().Err(res.Err()).Str("filePath", filepath.Ok().toString()).Msg("error saving").AsError();
    }
  }
  async close() {
    await this.gateway.close(this.url());
    this._onClosed.forEach((fn) => fn());
    return Result5.Ok(void 0);
  }
  destroy() {
    return this.gateway.destroy(this.url());
  }
};

// src/blockstore/store-factory.ts
function ensureIsIndex(url, isIndex) {
  if (isIndex) {
    return url.build().setParam("index", isIndex).URI();
  }
  return url.build().delParam("index").URI();
}
function ensureName(name, url) {
  if (!url.hasParam("name")) {
    return url.build().setParam("name", name).URI();
  }
  return url;
}
var storeFactory = /* @__PURE__ */ new Map();
function buildURL(optURL, loader) {
  const storeOpts = loader.ebOpts.store;
  const obuItem = Array.from(storeFactory.values()).find((items) => items.overrideBaseURL);
  let obuUrl;
  if (obuItem && obuItem.overrideBaseURL) {
    obuUrl = URI6.from(obuItem.overrideBaseURL);
  }
  const ret = ensureIsIndex(
    URI6.from(optURL || obuUrl || dataDir(loader.sthis, loader.name, storeOpts.stores?.base)),
    storeOpts.isIndex
  );
  return ret;
}
var onceGateway = new KeyedResolvOnce2();
async function getGatewayFromURL(url, sthis) {
  return onceGateway.get(url.toString()).once(async () => {
    const item = storeFactory.get(url.protocol);
    if (item) {
      const ret = {
        gateway: await item.gateway(sthis),
        test: await item.test(sthis)
      };
      const res = await ret.gateway.start(url);
      if (res.isErr()) {
        sthis.logger.Error().Result("start", res).Msg("start failed");
        return void 0;
      }
      return ret;
    }
    sthis.logger.Warn().Url(url).Msg("unsupported protocol");
    return void 0;
  });
}
function registerStoreProtocol(item) {
  let protocol = item.protocol;
  if (!protocol.endsWith(":")) {
    protocol += ":";
  }
  if (storeFactory.has(protocol)) {
    if (!item.overrideBaseURL && storeFactory.get(protocol) !== item) {
      throw new Error(`we need a logger here`);
      return () => {
      };
    }
  }
  if (item.overrideBaseURL) {
    Array.from(storeFactory.values()).forEach((items) => {
      items.overrideBaseURL = void 0;
    });
  }
  storeFactory.set(protocol, item);
  return () => {
    storeFactory.delete(protocol);
  };
}
var onceDataStoreFactory = new KeyedResolvOnce2();
async function dataStoreFactory(loader) {
  const url = ensureName(loader.name, buildURL(loader.ebOpts.store.stores?.data, loader)).build().setParam("store", "data").URI();
  const sthis = ensureSuperLog(loader.sthis, "dataStoreFactory", { url: url.toString() });
  return onceDataStoreFactory.get(url.toString()).once(async () => {
    const gateway = await getGatewayFromURL(url, sthis);
    if (!gateway) {
      throw sthis.logger.Error().Url(url).Msg("gateway not found").AsError();
    }
    const store = new DataStoreImpl(sthis, loader.name, url, {
      gateway: gateway.gateway,
      keybag: () => getKeyBag(loader.sthis, {
        ...loader.ebOpts.keyBag
      })
    });
    return store;
  });
}
var onceMetaStoreFactory = new KeyedResolvOnce2();
async function metaStoreFactory(loader) {
  const url = ensureName(loader.name, buildURL(loader.ebOpts.store.stores?.meta, loader)).build().setParam("store", "meta").URI();
  const sthis = ensureSuperLog(loader.sthis, "metaStoreFactory", { url: () => url.toString() });
  return onceMetaStoreFactory.get(url.toString()).once(async () => {
    sthis.logger.Debug().Str("protocol", url.protocol).Msg("pre-protocol switch");
    const gateway = await getGatewayFromURL(url, sthis);
    if (!gateway) {
      throw sthis.logger.Error().Url(url).Msg("gateway not found").AsError();
    }
    const store = new MetaStoreImpl(loader.sthis, loader.name, url, {
      gateway: gateway.gateway,
      keybag: () => getKeyBag(loader.sthis, {
        ...loader.ebOpts.keyBag
      })
    });
    return store;
  });
}
var onceRemoteWalFactory = new KeyedResolvOnce2();
async function remoteWalFactory(loader) {
  const url = ensureName(loader.name, buildURL(loader.ebOpts.store.stores?.wal, loader)).build().setParam("store", "wal").URI();
  const sthis = ensureSuperLog(loader.sthis, "remoteWalFactory", { url: url.toString() });
  return onceRemoteWalFactory.get(url.toString()).once(async () => {
    const gateway = await getGatewayFromURL(url, sthis);
    if (!gateway) {
      throw sthis.logger.Error().Url(url).Msg("gateway not found").AsError();
    }
    sthis.logger.Debug().Str("prepared", url.toString()).Msg("produced");
    const store = new WALStoreImpl(loader, url, {
      gateway: gateway.gateway,
      keybag: () => getKeyBag(loader.sthis, {
        ...loader.ebOpts.keyBag
      })
    });
    return store;
  });
}
async function testStoreFactory(url, sthis) {
  sthis = ensureSuperLog(sthis, "testStoreFactory");
  const gateway = await getGatewayFromURL(url, sthis);
  if (!gateway) {
    throw sthis.logger.Error().Url(url).Msg("gateway not found").AsError();
  }
  return gateway.test;
}
async function ensureStart(store, logger) {
  const ret = await store.start();
  if (ret.isErr()) {
    throw logger.Error().Result("start", ret).Msg("start failed").AsError();
  }
  logger.Debug().Url(ret.Ok(), "prepared").Msg("produced");
  return store;
}
function toStoreRuntime(opts, sthis) {
  const logger = ensureLogger(sthis, "toStoreRuntime", {});
  return {
    makeMetaStore: async (loader) => {
      logger.Debug().Str("fromOpts", "" + !!loader.ebOpts.store.makeMetaStore).Msg("makeMetaStore");
      return ensureStart(await (loader.ebOpts.store.makeMetaStore || metaStoreFactory)(loader), logger);
    },
    makeDataStore: async (loader) => {
      logger.Debug().Str("fromOpts", "" + !!loader.ebOpts.store.makeDataStore).Msg("makeDataStore");
      return ensureStart(await (loader.ebOpts.store.makeDataStore || dataStoreFactory)(loader), logger);
    },
    makeWALStore: async (loader) => {
      logger.Debug().Str("fromOpts", "" + !!loader.ebOpts.store.makeWALStore).Msg("makeRemoteWAL");
      return ensureStart(await (loader.ebOpts.store.makeWALStore || remoteWalFactory)(loader), logger);
    },
    encodeFile: opts.encodeFile || encodeFile,
    decodeFile: opts.decodeFile || decodeFile
  };
}
if (runtimeFn3().isNodeIsh || runtimeFn3().isDeno) {
  registerStoreProtocol({
    protocol: "file:",
    gateway: async (sthis) => {
      const { GatewayImpl } = await import("@fireproof/core/node");
      return new GatewayImpl(sthis);
    },
    test: async (sthis) => {
      const { GatewayTestImpl } = await import("@fireproof/core/node");
      return new GatewayTestImpl(sthis);
    }
  });
}
if (runtimeFn3().isBrowser) {
  registerStoreProtocol({
    protocol: "indexdb:",
    gateway: async (sthis) => {
      const { GatewayImpl } = await import("@fireproof/core/web");
      return new GatewayImpl(sthis);
    },
    test: async (sthis) => {
      const { GatewayTestImpl } = await import("@fireproof/core/web");
      return new GatewayTestImpl(sthis);
    }
  });
}

// src/blockstore/store-remote.ts
async function RemoteDataStore(sthis, name, url, opts) {
  const ds = new DataStoreImpl(sthis, name, url, opts);
  await ds.start();
  return ds;
}
async function RemoteMetaStore(sthis, name, url, opts) {
  const ms = new MetaStoreImpl(
    sthis,
    name,
    url,
    opts
    /* , true*/
  );
  await ms.start();
  return ms;
}

// src/blockstore/connection-base.ts
var ConnectionBase = class {
  constructor(url, logger) {
    this.loaded = Promise.resolve();
    this.logger = logger;
    this.url = url;
  }
  async refresh() {
    await throwFalsy(throwFalsy(this.loader).remoteMetaStore).load();
    await (await throwFalsy(this.loader).WALStore()).process();
  }
  async connect_X({ loader }) {
    if (!loader) throw this.logger.Error().Msg("loader is required").AsError();
    await this.connectMeta_X({ loader });
    await this.connectStorage_X({ loader });
  }
  async connectMeta_X({ loader }) {
    if (!loader) throw this.logger.Error().Msg("connectMeta_X: loader is required").AsError();
    this.loader = loader;
    await this.onConnect();
    const metaUrl = this.url.build().defParam("store", "meta").URI();
    const gateway = await getGatewayFromURL(metaUrl, this.loader.sthis);
    if (!gateway) throw this.logger.Error().Url(metaUrl).Msg("connectMeta_X: gateway is required").AsError();
    const dbName = metaUrl.getParam("name");
    if (!dbName) throw this.logger.Error().Url(metaUrl).Msg("connectMeta_X: name is required").AsError();
    const remote = await RemoteMetaStore(loader.sthis, dbName, metaUrl, {
      gateway: gateway.gateway,
      keybag: () => getKeyBag(loader.sthis, loader.ebOpts.keyBag),
      loader
    });
    this.loader.remoteMetaStore = remote;
    this.loaded = this.loader.ready().then(async () => {
      return remote.load().then(async () => {
        return (await throwFalsy(this.loader).WALStore()).process();
      });
    });
  }
  async connectStorage_X({ loader }) {
    if (!loader) throw this.logger.Error().Msg("connectStorage_X: loader is required").AsError();
    this.loader = loader;
    const dataUrl = this.url.build().defParam("store", "data").URI();
    const gateway = await getGatewayFromURL(dataUrl, this.loader.sthis);
    if (!gateway) throw this.logger.Error().Url(dataUrl).Msg("connectStorage_X: gateway is required").AsError();
    const name = dataUrl.getParam("name");
    if (!name) throw this.logger.Error().Url(dataUrl).Msg("connectStorage_X: name is required").AsError;
    loader.remoteCarStore = await RemoteDataStore(loader.sthis, name, this.url, {
      gateway: gateway.gateway,
      keybag: () => getKeyBag(loader.sthis, this.loader?.ebOpts.keyBag)
    });
    loader.remoteFileStore = loader.remoteCarStore;
  }
  // move this stuff to connect
  // async getDashboardURL(compact = true) {
  //   const baseUrl = 'https://dashboard.fireproof.storage/'
  //   if (!this.loader?.remoteCarStore) return new URL('/howto', baseUrl)
  //   // if (compact) {
  //   //   await this.compact()
  //   // }
  //   const currents = await this.loader?.metaStore?.load()
  //   if (!currents) throw new Error("Can't sync empty database: save data first")
  //   if (currents.length > 1)
  //     throw new Error("Can't sync database with split heads: make an update first")
  //   const current = currents[0]
  //   const params = {
  //     car: current.car.toString()
  //   }
  //   if (current.key) {
  //     // @ts-ignore
  //     params.key = current.key.toString()
  //   }
  //   // @ts-ignore
  //   if (this.name) {
  //     // @ts-ignore
  //     params.name = this.name
  //   }
  //   const url = new URL('/import#' + new URLSearchParams(params).toString(), baseUrl)
  //   console.log('Import to dashboard: ' + url.toString())
  //   return url
  // }
  // openDashboard() {
  //   void this.getDashboardURL().then(url => {
  //     if (url) window.open(url.toString(), '_blank')
  //   })
  // }
};

// src/crdt-helpers.ts
function time(tag) {
}
function timeEnd(tag) {
}
function toString(key, logger) {
  switch (typeof key) {
    case "string":
    case "number":
      return key.toString();
    default:
      throw logger.Error().Msg("Invalid key type").AsError();
  }
}
function sanitizeDocumentFields(obj) {
  if (Array.isArray(obj)) {
    return obj.map((item) => {
      if (typeof item === "object" && item !== null) {
        return sanitizeDocumentFields(item);
      }
      return item;
    });
  } else if (typeof obj === "object" && obj !== null) {
    if (obj instanceof Date) {
      return obj.toISOString();
    }
    const typedObj = obj;
    const result = {};
    for (const key in typedObj) {
      if (Object.hasOwnProperty.call(typedObj, key)) {
        const value = typedObj[key];
        if (value === null || !Number.isNaN(value) && value !== void 0) {
          if (typeof value === "object" && !key.startsWith("_")) {
            if (value instanceof Date) {
              result[key] = value.toISOString();
            } else {
              const sanitized = sanitizeDocumentFields(value);
              result[key] = sanitized;
            }
          } else {
            result[key] = value;
          }
        }
      }
    }
    return result;
  }
  return obj;
}
async function applyBulkUpdateToCrdt(store, tblocks, head, updates, logger) {
  let result = null;
  if (updates.length > 1) {
    const batch = await Batch.create(tblocks, head);
    for (const update of updates) {
      const link = await writeDocContent(store, tblocks, update, logger);
      await batch.put(toString(update.id, logger), link);
    }
    result = await batch.commit();
  } else if (updates.length === 1) {
    const link = await writeDocContent(store, tblocks, updates[0], logger);
    result = await put(tblocks, head, toString(updates[0].id, logger), link);
  }
  if (!result) throw logger.Error().Uint64("updates.len", updates.length).Msg("Missing result").AsError();
  if (result.event) {
    for (const { cid, bytes } of [
      ...result.additions,
      // ...result.removals,
      result.event
    ]) {
      tblocks.putSync(cid, bytes);
    }
  }
  return { head: result.head };
}
async function writeDocContent(store, blocks, update, logger) {
  let value;
  if (update.del) {
    value = { del: true };
  } else {
    if (!update.value) throw logger.Error().Msg("Missing value").AsError();
    await processFiles(store, blocks, update.value, logger);
    value = { doc: update.value };
  }
  const block = await encode({ value, hasher: hasher5, codec });
  blocks.putSync(block.cid, block.bytes);
  return block.cid;
}
async function processFiles(store, blocks, doc, logger) {
  if (doc._files) {
    await processFileset(logger, store, blocks, doc._files);
  }
  if (doc._publicFiles) {
    await processFileset(
      logger,
      store,
      blocks,
      doc._publicFiles
      /*, true*/
    );
  }
}
async function processFileset(logger, store, blocks, files) {
  const dbBlockstore = blocks.parent;
  if (!dbBlockstore.loader) throw logger.Error().Msg("Missing loader, database name is required").AsError();
  const t = new CarTransaction(dbBlockstore);
  const didPut = [];
  for (const filename in files) {
    if (File === files[filename].constructor) {
      const file = files[filename];
      const { cid, blocks: fileBlocks } = await store.encodeFile(file);
      didPut.push(filename);
      for (const block of fileBlocks) {
        t.putSync(block.cid, block.bytes);
      }
      files[filename] = { cid, type: file.type, size: file.size };
    } else {
      const { cid, type, size, car } = files[filename];
      if (cid && type && size && car) {
        files[filename] = { cid, type, size, car };
      }
    }
  }
  if (didPut.length) {
    const car = await dbBlockstore.loader.commitFiles(
      t,
      { files }
    );
    if (car) {
      for (const name of didPut) {
        files[name] = { car, ...files[name] };
      }
    }
  }
}
async function getValueFromCrdt(blocks, head, key, logger) {
  if (!head.length) throw logger.Debug().Msg("Getting from an empty database").AsError();
  const link = await get(blocks, head, key);
  if (!link) throw logger.Error().Str("key", key).Msg(`Missing key`).AsError();
  return await getValueFromLink(blocks, link, logger);
}
function readFiles(blocks, { doc }) {
  if (!doc) return;
  if (doc._files) {
    readFileset(blocks, doc._files);
  }
  if (doc._publicFiles) {
    readFileset(blocks, doc._publicFiles, true);
  }
}
function readFileset(blocks, files, isPublic = false) {
  for (const filename in files) {
    const fileMeta = files[filename];
    if (fileMeta.cid) {
      if (isPublic) {
        fileMeta.url = `https://${fileMeta.cid.toString()}.ipfs.w3s.link/`;
      }
      if (fileMeta.car) {
        fileMeta.file = async () => await blocks.ebOpts.storeRuntime.decodeFile(
          {
            get: async (cid) => {
              return await blocks.getFile(throwFalsy(fileMeta.car), cid);
            }
          },
          fileMeta.cid,
          fileMeta
        );
      }
    }
    files[filename] = fileMeta;
  }
}
async function getValueFromLink(blocks, link, logger) {
  const block = await blocks.get(link);
  if (!block) throw logger.Error().Str("link", link.toString()).Msg(`Missing linked block`).AsError();
  const { value } = await decode({ bytes: block.bytes, hasher: hasher5, codec });
  const cvalue = {
    ...value,
    cid: link
  };
  readFiles(blocks, cvalue);
  return cvalue;
}
var DirtyEventFetcher = class extends EventFetcher {
  constructor(logger, blocks) {
    super(blocks);
    this.logger = logger;
  }
  async get(link) {
    try {
      return super.get(link);
    } catch (e) {
      this.logger.Error().Ref("link", link.toString()).Err(e).Msg("Missing event");
      return { value: void 0 };
    }
  }
};
async function clockChangesSince(blocks, head, since, opts, logger) {
  const eventsFetcher = opts.dirty ? new DirtyEventFetcher(logger, blocks) : new EventFetcher(blocks);
  const keys = /* @__PURE__ */ new Set();
  const updates = await gatherUpdates(
    blocks,
    eventsFetcher,
    head,
    since,
    [],
    keys,
    /* @__PURE__ */ new Set(),
    opts.limit || Infinity,
    logger
  );
  return { result: updates.reverse(), head };
}
async function gatherUpdates(blocks, eventsFetcher, head, since, updates = [], keys, didLinks, limit, logger) {
  if (limit <= 0) return updates;
  const sHead = head.map((l) => l.toString());
  for (const link of since) {
    if (sHead.includes(link.toString())) {
      return updates;
    }
  }
  for (const link of head) {
    if (didLinks.has(link.toString())) continue;
    didLinks.add(link.toString());
    const { value: event } = await eventsFetcher.get(link);
    if (!event) continue;
    const { type } = event.data;
    let ops = [];
    if (type === "batch") {
      ops = event.data.ops;
    } else if (type === "put") {
      ops = [event.data];
    }
    for (let i = ops.length - 1; i >= 0; i--) {
      const { key, value } = ops[i];
      if (!keys.has(key)) {
        const docValue = await getValueFromLink(blocks, value, logger);
        updates.push({ id: key, value: docValue.doc, del: docValue.del, clock: link });
        limit--;
        keys.add(key);
      }
    }
    if (event.parents) {
      updates = await gatherUpdates(blocks, eventsFetcher, event.parents, since, updates, keys, didLinks, limit, logger);
    }
  }
  return updates;
}
async function* getAllEntries(blocks, head, logger) {
  for await (const [key, link] of entries(blocks, head)) {
    const docValue = await getValueFromLink(blocks, link, logger);
    yield { id: key, value: docValue.doc, del: docValue.del };
  }
}
async function* clockVis(blocks, head) {
  for await (const line of vis(blocks, head)) {
    yield line;
  }
}
var isCompacting = false;
async function doCompact(blockLog, head, logger) {
  if (isCompacting) {
    return;
  }
  isCompacting = true;
  time("compact head");
  for (const cid of head) {
    const bl = await blockLog.get(cid);
    if (!bl) throw logger.Error().Ref("cid", cid).Msg("Missing head block").AsError();
  }
  timeEnd("compact head");
  time("compact all entries");
  for await (const _entry of getAllEntries(blockLog, head, logger)) {
    continue;
  }
  timeEnd("compact all entries");
  time("compact clock vis");
  for await (const _line of vis(blockLog, head)) {
  }
  timeEnd("compact clock vis");
  time("compact root");
  const result = await root(blockLog, head);
  timeEnd("compact root");
  time("compact root blocks");
  for (const { cid, bytes } of [...result.additions, ...result.removals]) {
    blockLog.loggedBlocks.putSync(cid, bytes);
  }
  timeEnd("compact root blocks");
  time("compact changes");
  await clockChangesSince(blockLog, head, [], {}, logger);
  timeEnd("compact changes");
  isCompacting = false;
}
async function getBlock(blocks, cidString) {
  const block = await blocks.get(parse3(cidString));
  if (!block) throw new Error(`Missing block ${cidString}`);
  const { cid, value } = await decode({ bytes: block.bytes, codec, hasher: hasher5 });
  return new Block({ cid, value, bytes: block.bytes });
}

// src/indexer-helpers.ts
import { sha256 as hasher6 } from "multiformats/hashes/sha2";
import * as codec2 from "@fireproof/vendor/@ipld/dag-cbor";
import charwise from "charwise";
import * as DbIndex from "prolly-trees/db-index";
import { bf, simpleCompare } from "prolly-trees/utils";
import { nocache as cache } from "prolly-trees/cache";
var IndexTree = class {
};
function refCompare(aRef, bRef) {
  if (Number.isNaN(aRef)) return -1;
  if (Number.isNaN(bRef)) throw new Error("ref may not be Infinity or NaN");
  if (aRef === Infinity) return 1;
  return simpleCompare(aRef, bRef);
}
function compare(a, b) {
  const [aKey, aRef] = a;
  const [bKey, bRef] = b;
  const comp = simpleCompare(aKey, bKey);
  if (comp !== 0) return comp;
  return refCompare(aRef, bRef);
}
var byKeyOpts = { cache, chunker: bf(30), codec: codec2, hasher: hasher6, compare };
var byIdOpts = { cache, chunker: bf(30), codec: codec2, hasher: hasher6, compare: simpleCompare };
function indexEntriesForChanges(changes, mapFn) {
  const indexEntries = [];
  changes.forEach(({ id: key, value, del }) => {
    if (del || !value) return;
    let mapCalled = false;
    const mapReturn = mapFn({ ...value, _id: key }, (k, v) => {
      mapCalled = true;
      if (typeof k === "undefined") return;
      indexEntries.push({
        key: [charwise.encode(k), key],
        value: v || null
      });
    });
    if (!mapCalled && mapReturn) {
      indexEntries.push({
        key: [charwise.encode(mapReturn), key],
        value: null
      });
    }
  });
  return indexEntries;
}
function makeProllyGetBlock(blocks) {
  return async (address) => {
    const block = await blocks.get(address);
    if (!block) throw new Error(`Missing block ${address.toString()}`);
    const { cid, bytes } = block;
    return create({ cid, bytes, hasher: hasher6, codec: codec2 });
  };
}
async function bulkIndex(tblocks, inIndex, indexEntries, opts) {
  if (!indexEntries.length) return inIndex;
  if (!inIndex.root) {
    if (!inIndex.cid) {
      let returnRootBlock = void 0;
      let returnNode = void 0;
      for await (const node of await DbIndex.create({
        get: makeProllyGetBlock(tblocks),
        list: indexEntries,
        ...opts
      })) {
        const block = await node.block;
        await tblocks.put(block.cid, block.bytes);
        returnRootBlock = block;
        returnNode = node;
      }
      if (!returnNode || !returnRootBlock) throw new Error("failed to create index");
      return { root: returnNode, cid: returnRootBlock.cid };
    } else {
      inIndex.root = await DbIndex.load({ cid: inIndex.cid, get: makeProllyGetBlock(tblocks), ...opts });
    }
  }
  const { root: root3, blocks: newBlocks } = await inIndex.root.bulk(indexEntries);
  if (root3) {
    for await (const block of newBlocks) {
      await tblocks.put(block.cid, block.bytes);
    }
    return { root: root3, cid: (await root3.block).cid };
  } else {
    return { root: void 0, cid: void 0 };
  }
}
async function loadIndex(tblocks, cid, opts) {
  return await DbIndex.load({ cid, get: makeProllyGetBlock(tblocks), ...opts });
}
async function applyQuery(crdt, resp, query) {
  if (query.descending) {
    resp.result = resp.result.reverse();
  }
  if (query.limit) {
    resp.result = resp.result.slice(0, query.limit);
  }
  if (query.includeDocs) {
    resp.result = await Promise.all(
      resp.result.map(async (row) => {
        const val = await crdt.get(row.id);
        const doc = val ? { ...val.doc, _id: row.id } : void 0;
        return { ...row, doc };
      })
    );
  }
  return {
    rows: resp.result.map(({ key, ...row }) => {
      return {
        key: charwise.decode(key),
        ...row
      };
    })
  };
}
function encodeRange(range) {
  return [charwise.encode(range[0]), charwise.encode(range[1])];
}
function encodeKey(key) {
  return charwise.encode(key);
}

// src/indexer.ts
function index(sthis, { _crdt }, name, mapFn, meta) {
  if (mapFn && meta) throw _crdt.logger.Error().Msg("cannot provide both mapFn and meta").AsError();
  if (mapFn && mapFn.constructor.name !== "Function") throw _crdt.logger.Error().Msg("mapFn must be a function").AsError();
  if (_crdt.indexers.has(name)) {
    const idx = _crdt.indexers.get(name);
    idx.applyMapFn(name, mapFn, meta);
  } else {
    const idx = new Index(sthis, _crdt, name, mapFn, meta);
    _crdt.indexers.set(name, idx);
  }
  return _crdt.indexers.get(name);
}
var Index = class {
  constructor(sthis, crdt, name, mapFn, meta) {
    this.mapFnString = "";
    this.byKey = new IndexTree();
    this.byId = new IndexTree();
    this.includeDocsDefault = false;
    this.logger = ensureLogger(sthis, "Index");
    this.blockstore = crdt.indexBlockstore;
    this.crdt = crdt;
    this.applyMapFn(name, mapFn, meta);
    this.name = name;
    if (!(this.mapFnString || this.initError)) throw this.logger.Error().Msg("missing mapFnString").AsError();
  }
  ready() {
    return Promise.all([this.blockstore.ready(), this.crdt.ready()]).then(() => {
    });
  }
  close() {
    return Promise.all([this.blockstore.close(), this.crdt.close()]).then(() => {
    });
  }
  destroy() {
    return Promise.all([this.blockstore.destroy(), this.crdt.destroy()]).then(() => {
    });
  }
  applyMapFn(name, mapFn, meta) {
    if (mapFn && meta) throw this.logger.Error().Msg("cannot provide both mapFn and meta").AsError();
    if (this.name && this.name !== name) throw this.logger.Error().Msg("cannot change name").AsError();
    this.name = name;
    try {
      if (meta) {
        if (this.indexHead && this.indexHead.map((c) => c.toString()).join() !== meta.head.map((c) => c.toString()).join()) {
          throw this.logger.Error().Msg("cannot apply different head meta").AsError();
        }
        if (this.mapFnString) {
          if (this.mapFnString !== meta.map) {
            this.logger.Warn().Msg(`cannot apply different mapFn meta: old mapFnString ${this.mapFnString} new mapFnString ${meta.map}`);
          } else {
            this.byId.cid = meta.byId;
            this.byKey.cid = meta.byKey;
            this.indexHead = meta.head;
          }
        } else {
          this.mapFnString = meta.map;
          this.byId.cid = meta.byId;
          this.byKey.cid = meta.byKey;
          this.indexHead = meta.head;
        }
      } else {
        if (this.mapFn) {
          if (mapFn) {
            if (this.mapFn.toString() !== mapFn.toString()) {
              this.logger.Error().Msg("cannot apply different mapFn app2");
            }
          }
        } else {
          if (!mapFn) {
            mapFn = (doc) => doc[name] ?? void 0;
          }
          if (this.mapFnString) {
            if (this.mapFnString !== mapFn.toString()) {
              this.logger.Error().Str("mapFnString", this.mapFnString).Str("mapFn", mapFn.toString()).Msg("cannot apply different mapFn app");
            }
          } else {
            this.mapFnString = mapFn.toString();
          }
          this.mapFn = mapFn;
        }
      }
      const matches = /=>\s*(.*)/.test(this.mapFnString);
      this.includeDocsDefault = matches;
    } catch (e) {
      this.initError = e;
    }
  }
  async query(opts = {}) {
    await this.ready();
    await this._updateIndex();
    await this._hydrateIndex();
    if (!this.byKey.root) {
      return await applyQuery(this.crdt, { result: [] }, opts);
    }
    if (this.includeDocsDefault && opts.includeDocs === void 0) opts.includeDocs = true;
    if (opts.range) {
      const eRange = encodeRange(opts.range);
      return await applyQuery(this.crdt, await throwFalsy(this.byKey.root).range(eRange[0], eRange[1]), opts);
    }
    if (opts.key) {
      const encodedKey = encodeKey(opts.key);
      return await applyQuery(this.crdt, await throwFalsy(this.byKey.root).get(encodedKey), opts);
    }
    if (Array.isArray(opts.keys)) {
      const results = await Promise.all(
        opts.keys.map(async (key) => {
          const encodedKey = encodeKey(key);
          return (await applyQuery(this.crdt, await throwFalsy(this.byKey.root).get(encodedKey), opts)).rows;
        })
      );
      return { rows: results.flat() };
    }
    if (opts.prefix) {
      if (!Array.isArray(opts.prefix)) opts.prefix = [opts.prefix];
      const start = [...opts.prefix, NaN];
      const end = [...opts.prefix, Infinity];
      const encodedR = encodeRange([start, end]);
      return await applyQuery(this.crdt, await this.byKey.root.range(...encodedR), opts);
    }
    const all = await this.byKey.root.getAllEntries();
    return await applyQuery(
      this.crdt,
      {
        // @ts-expect-error getAllEntries returns a different type than range
        result: all.result.map(({ key: [k, id], value }) => ({
          key: k,
          id,
          value
        }))
      },
      opts
    );
  }
  _resetIndex() {
    this.byId = new IndexTree();
    this.byKey = new IndexTree();
    this.indexHead = void 0;
  }
  async _hydrateIndex() {
    if (this.byId.root && this.byKey.root) return;
    if (!this.byId.cid || !this.byKey.cid) return;
    this.byId.root = await loadIndex(this.blockstore, this.byId.cid, byIdOpts);
    this.byKey.root = await loadIndex(this.blockstore, this.byKey.cid, byKeyOpts);
  }
  async _updateIndex() {
    await this.ready();
    if (this.initError) throw this.initError;
    if (!this.mapFn) throw this.logger.Error().Msg("No map function defined").AsError();
    let result, head;
    if (!this.indexHead || this.indexHead.length === 0) {
      ({ result, head } = await this.crdt.allDocs());
    } else {
      ({ result, head } = await this.crdt.changes(this.indexHead));
    }
    if (result.length === 0) {
      this.indexHead = head;
    }
    let staleKeyIndexEntries = [];
    let removeIdIndexEntries = [];
    if (this.byId.root) {
      const removeIds = result.map(({ id: key }) => key);
      const { result: oldChangeEntries } = await this.byId.root.getMany(removeIds);
      staleKeyIndexEntries = oldChangeEntries.map((key) => ({ key, del: true }));
      removeIdIndexEntries = oldChangeEntries.map((key) => ({ key: key[1], del: true }));
    }
    const indexEntries = indexEntriesForChanges(result, this.mapFn);
    const byIdIndexEntries = indexEntries.map(({ key }) => ({
      key: key[1],
      value: key
    }));
    const indexerMeta = { indexes: /* @__PURE__ */ new Map() };
    for (const [name, indexer] of this.crdt.indexers) {
      if (indexer.indexHead) {
        indexerMeta.indexes?.set(name, {
          byId: indexer.byId.cid,
          byKey: indexer.byKey.cid,
          head: indexer.indexHead,
          map: indexer.mapFnString,
          name: indexer.name
        });
      }
    }
    if (result.length === 0) {
      return indexerMeta;
    }
    const { meta } = await this.blockstore.transaction(async (tblocks) => {
      this.byId = await bulkIndex(tblocks, this.byId, removeIdIndexEntries.concat(byIdIndexEntries), byIdOpts);
      this.byKey = await bulkIndex(tblocks, this.byKey, staleKeyIndexEntries.concat(indexEntries), byKeyOpts);
      this.indexHead = head;
      if (this.byId.cid && this.byKey.cid) {
        const idxMeta = {
          byId: this.byId.cid,
          byKey: this.byKey.cid,
          head,
          map: this.mapFnString,
          name: this.name
        };
        indexerMeta.indexes?.set(this.name, idxMeta);
      }
      return indexerMeta;
    });
    return meta;
  }
};

// src/crdt-clock.ts
import { advance } from "@fireproof/vendor/@web3-storage/pail/clock";
import { root as root2 } from "@fireproof/vendor/@web3-storage/pail/crdt";
import { ResolveOnce as ResolveOnce5 } from "@adviser/cement";

// src/apply-head-queue.ts
function applyHeadQueue(worker, logger) {
  const queue = [];
  let isProcessing = false;
  async function* process() {
    if (isProcessing || queue.length === 0) return;
    isProcessing = true;
    const allUpdates = [];
    try {
      while (queue.length > 0) {
        queue.sort((a, b) => b.updates ? 1 : -1);
        const task = queue.shift();
        if (!task) continue;
        await worker(task.newHead, task.prevHead, task.updates !== void 0).catch((e) => {
          throw logger.Error().Err(e).Msg("int_applyHead worker error").AsError();
        });
        if (task.updates) {
          allUpdates.push(...task.updates);
        }
        if (!queue.some((t) => t.updates) || task.updates) {
          const allTasksHaveUpdates = queue.every((task2) => task2.updates !== null);
          yield { updates: allUpdates, all: allTasksHaveUpdates };
          allUpdates.length = 0;
        }
      }
    } finally {
      isProcessing = false;
      const generator = process();
      let result = await generator.next();
      while (!result.done) {
        result = await generator.next();
      }
    }
  }
  return {
    push(task) {
      queue.push(task);
      return process();
    },
    size() {
      return queue.length;
    }
  };
}

// src/crdt-clock.ts
var CRDTClock = class {
  constructor(blockstore) {
    // todo: track local and remote clocks independently, merge on read
    // that way we can drop the whole remote if we need to
    // should go with making sure the local clock only references locally available blockstore on write
    this.head = [];
    this.zoomers = /* @__PURE__ */ new Set();
    this.watchers = /* @__PURE__ */ new Set();
    this.emptyWatchers = /* @__PURE__ */ new Set();
    this._ready = new ResolveOnce5();
    this.blockstore = blockstore;
    this.logger = ensureLogger(blockstore.sthis, "CRDTClock");
    this.applyHeadQueue = applyHeadQueue(this.int_applyHead.bind(this), this.logger);
  }
  async ready() {
    return this._ready.once(async () => {
      await this.blockstore.ready();
    });
  }
  async close() {
    await this.blockstore.close();
  }
  setHead(head) {
    this.head = head;
  }
  async applyHead(newHead, prevHead, updates) {
    for await (const { updates: updatesAcc, all } of this.applyHeadQueue.push({
      newHead,
      prevHead,
      updates
    })) {
      return this.processUpdates(updatesAcc, all, prevHead);
    }
  }
  async processUpdates(updatesAcc, all, prevHead) {
    let internalUpdates = updatesAcc;
    if (this.watchers.size && !all) {
      const changes = await clockChangesSince(throwFalsy(this.blockstore), this.head, prevHead, {}, this.logger);
      internalUpdates = changes.result;
    }
    this.zoomers.forEach((fn) => fn());
    this.notifyWatchers(internalUpdates || []);
  }
  notifyWatchers(updates) {
    this.emptyWatchers.forEach((fn) => fn());
    this.watchers.forEach((fn) => fn(updates || []));
  }
  onTick(fn) {
    this.watchers.add(fn);
  }
  onTock(fn) {
    this.emptyWatchers.add(fn);
  }
  onZoom(fn) {
    this.zoomers.add(fn);
  }
  async int_applyHead(newHead, prevHead, localUpdates) {
    const noLoader = !localUpdates;
    const ogHead = sortClockHead(this.head);
    newHead = sortClockHead(newHead);
    if (compareClockHeads(ogHead, newHead)) {
      return;
    }
    const ogPrev = sortClockHead(prevHead);
    if (compareClockHeads(ogHead, ogPrev)) {
      this.setHead(newHead);
      return;
    }
    if (!this.blockstore) {
      throw this.logger.Error().Msg("missing blockstore").AsError();
    }
    await validateBlocks(this.logger, newHead, this.blockstore);
    if (!this.transaction) {
      this.transaction = this.blockstore.openTransaction({ noLoader, add: false });
    }
    const tblocks = this.transaction;
    const advancedHead = await advanceBlocks(this.logger, newHead, tblocks, this.head);
    const result = await root2(tblocks, advancedHead);
    for (const { cid, bytes } of [
      ...result.additions
      // ...result.removals
    ]) {
      tblocks.putSync(cid, bytes);
    }
    if (!noLoader) {
      await this.blockstore.commitTransaction(tblocks, { head: advancedHead }, { add: false, noLoader });
      this.transaction = void 0;
    }
    this.setHead(advancedHead);
  }
};
function sortClockHead(clockHead) {
  return clockHead.sort((a, b) => a.toString().localeCompare(b.toString()));
}
async function validateBlocks(logger, newHead, blockstore) {
  if (!blockstore) throw logger.Error().Msg("missing blockstore");
  newHead.map(async (cid) => {
    const got = await blockstore.get(cid);
    if (!got) {
      throw logger.Error().Str("cid", cid.toString()).Msg("int_applyHead missing block").AsError();
    }
  });
}
function compareClockHeads(head1, head2) {
  return head1.toString() === head2.toString();
}
async function advanceBlocks(logger, newHead, tblocks, head) {
  for (const cid of newHead) {
    try {
      head = await advance(tblocks, head, cid);
    } catch (e) {
      logger.Debug().Err(e).Msg("failed to advance head");
      continue;
    }
  }
  return head;
}

// src/crdt.ts
var CRDT = class {
  constructor(sthis, name, opts = {}) {
    this.indexers = /* @__PURE__ */ new Map();
    this.onceReady = new ResolveOnce6();
    this.sthis = sthis;
    this.name = name;
    this.logger = ensureLogger(sthis, "CRDT");
    this.opts = opts;
    this.blockstore = blockstoreFactory(sthis, {
      name,
      applyMeta: async (meta) => {
        const crdtMeta = meta;
        if (!crdtMeta.head) throw this.logger.Error().Msg("missing head").AsError();
        await this.clock.applyHead(crdtMeta.head, []);
      },
      compact: async (blocks) => {
        await doCompact(blocks, this.clock.head, this.logger);
        return { head: this.clock.head };
      },
      autoCompact: this.opts.autoCompact || 100,
      store: { ...this.opts.store, isIndex: void 0 },
      public: this.opts.public,
      meta: this.opts.meta,
      threshold: this.opts.threshold
    });
    this.indexBlockstore = blockstoreFactory(sthis, {
      name,
      applyMeta: async (meta) => {
        const idxCarMeta = meta;
        if (!idxCarMeta.indexes) throw this.logger.Error().Msg("missing indexes").AsError();
        for (const [name2, idx] of Object.entries(idxCarMeta.indexes)) {
          index(this.sthis, { _crdt: this }, name2, void 0, idx);
        }
      },
      store: { ...this.opts.store, isIndex: this.opts.store?.isIndex || "idx" },
      public: this.opts.public
    });
    this.clock = new CRDTClock(this.blockstore);
    this.clock.onZoom(() => {
      for (const idx of this.indexers.values()) {
        idx._resetIndex();
      }
    });
  }
  async bulk(updates) {
    await this.ready();
    const prevHead = [...this.clock.head];
    updates = updates.map((dupdate) => ({
      ...dupdate,
      value: sanitizeDocumentFields(dupdate.value)
    }));
    const done = await this.blockstore.transaction(async (blocks) => {
      const { head } = await applyBulkUpdateToCrdt(
        this.blockstore.ebOpts.storeRuntime,
        blocks,
        this.clock.head,
        updates,
        this.logger
      );
      updates = updates.map((dupdate) => {
        readFiles(this.blockstore, { doc: dupdate.value });
        return dupdate;
      });
      return { head };
    });
    await this.clock.applyHead(done.meta.head, prevHead, updates);
    return done.meta;
  }
  async ready() {
    return this.onceReady.once(async () => {
      try {
        await Promise.all([this.blockstore.ready(), this.indexBlockstore.ready(), this.clock.ready()]);
      } catch (e) {
        throw this.logger.Error().Err(e).Msg(`CRDT is not ready`).AsError();
      }
    });
  }
  async close() {
    await Promise.all([this.blockstore.close(), this.indexBlockstore.close(), this.clock.close()]);
  }
  async destroy() {
    await Promise.all([this.blockstore.destroy(), this.indexBlockstore.destroy()]);
  }
  // if (snap) await this.clock.applyHead(crdtMeta.head, this.clock.head)
  async allDocs() {
    await this.ready();
    const result = [];
    for await (const entry of getAllEntries(this.blockstore, this.clock.head, this.logger)) {
      result.push(entry);
    }
    return { result, head: this.clock.head };
  }
  async vis() {
    await this.ready();
    const txt = [];
    for await (const line of clockVis(this.blockstore, this.clock.head)) {
      txt.push(line);
    }
    return txt.join("\n");
  }
  async getBlock(cidString) {
    await this.ready();
    return await getBlock(this.blockstore, cidString);
  }
  async get(key) {
    await this.ready();
    const result = await getValueFromCrdt(this.blockstore, this.clock.head, key, this.logger);
    if (result.del) return void 0;
    return result;
  }
  async changes(since = [], opts = {}) {
    await this.ready();
    return await clockChangesSince(this.blockstore, this.clock.head, since, opts, this.logger);
  }
  async compact() {
    const blocks = this.blockstore;
    return await blocks.compact();
  }
};

// src/database.ts
var Database = class {
  constructor(name, opts) {
    this.opts = {};
    this._listening = false;
    this._listeners = /* @__PURE__ */ new Set();
    this._noupdate_listeners = /* @__PURE__ */ new Set();
    this._ready = new ResolveOnce7();
    this.name = name;
    this.opts = opts || this.opts;
    this.sthis = ensureSuperThis(this.opts);
    this.logger = ensureLogger(this.sthis, "Database");
    this._crdt = new CRDT(this.sthis, name, this.opts);
    this.blockstore = this._crdt.blockstore;
    this._writeQueue = writeQueue(async (updates) => {
      return await this._crdt.bulk(updates);
    });
    this._crdt.clock.onTock(() => {
      this._no_update_notify();
    });
  }
  static {
    this.databases = /* @__PURE__ */ new Map();
  }
  /**
   * Close the database and release resources
   */
  async close() {
    await this.ready();
    await this._crdt.close();
    await this.blockstore.close();
  }
  /**
   * Destroy the database and release all resources
   */
  async destroy() {
    await this.ready();
    await this._crdt.destroy();
    await this.blockstore.destroy();
  }
  async ready() {
    return this._ready.once(async () => {
      await this.sthis.start();
      await this._crdt.ready();
      await this.blockstore.ready();
    });
  }
  /**
   * Get a document from the database
   * @param id - the document id
   * @returns the document with the _id
   * @throws NotFoundError if the document is not found
   */
  async get(id) {
    if (!id) throw this.logger.Error().Str("db", this.name).Msg(`Doc id is required`).AsError();
    await this.ready();
    this.logger.Debug().Str("id", id).Msg("get");
    const got = await this._crdt.get(id).catch((e) => {
      throw new NotFoundError(`Not found: ${id} - ${e.message}`);
    });
    if (!got) throw new NotFoundError(`Not found: ${id}`);
    const { doc } = got;
    return { ...doc, _id: id };
  }
  /**
   * Put a document from the database
   * @param doc - the document to put
   * @returns add DocResponse with the id and clock
   */
  async put(doc) {
    await this.ready();
    this.logger.Debug().Str("id", doc._id).Msg("put");
    const { _id, ...value } = doc;
    const docId = _id || this.sthis.timeOrderedNextId().str;
    const result = await this._writeQueue.push({
      id: docId,
      value: {
        ...value,
        _id: docId
      }
    });
    return { id: docId, clock: result?.head, name: this.name };
  }
  /**
   * delete a document from the database
   * @param id Document id
   * @returns DocResponse with the id and clock
   */
  async del(id) {
    await this.ready();
    this.logger.Debug().Str("id", id).Msg("del");
    const result = await this._writeQueue.push({ id, del: true });
    return { id, clock: result?.head, name: this.name };
  }
  async changes(since = [], opts = {}) {
    await this.ready();
    this.logger.Debug().Any("since", since).Any("opts", opts).Msg("changes");
    const { result, head } = await this._crdt.changes(since, opts);
    const rows = result.map(({ id: key, value, del, clock }) => ({
      key,
      value: del ? { _id: key, _deleted: true } : { _id: key, ...value },
      clock
    }));
    return { rows, clock: head, name: this.name };
  }
  async allDocs(opts = {}) {
    await this.ready();
    this.logger.Debug().Msg("allDocs");
    const { result, head } = await this._crdt.allDocs();
    const rows = result.map(({ id: key, value, del }) => ({
      key,
      value: del ? { _id: key, _deleted: true } : { _id: key, ...value }
    }));
    return { rows, clock: head, name: this.name };
  }
  async allDocuments() {
    return this.allDocs();
  }
  subscribe(listener, updates) {
    this.logger.Debug().Bool("updates", updates).Msg("subscribe");
    if (updates) {
      if (!this._listening) {
        this._listening = true;
        this._crdt.clock.onTick((updates2) => {
          void this._notify(updates2);
        });
      }
      this._listeners.add(listener);
      return () => {
        this._listeners.delete(listener);
      };
    } else {
      this._noupdate_listeners.add(listener);
      return () => {
        this._noupdate_listeners.delete(listener);
      };
    }
  }
  // todo if we add this onto dbs in fireproof.ts then we can make index.ts a separate package
  async query(field, opts = {}) {
    await this.ready();
    this.logger.Debug().Any("field", field).Any("opts", opts).Msg("query");
    const _crdt = this._crdt;
    const idx = typeof field === "string" ? index(this.sthis, { _crdt }, field) : index(this.sthis, { _crdt }, makeName(field.toString()), field);
    return await idx.query(opts);
  }
  async compact() {
    await this.ready();
    await this._crdt.compact();
  }
  async _notify(updates) {
    await this.ready();
    if (this._listeners.size) {
      const docs = updates.map(({ id, value }) => ({ ...value, _id: id }));
      for (const listener of this._listeners) {
        await (async () => await listener(docs))().catch((e) => {
          this.logger.Error().Err(e).Msg("subscriber error");
        });
      }
    }
  }
  async _no_update_notify() {
    await this.ready();
    if (this._noupdate_listeners.size) {
      for (const listener of this._noupdate_listeners) {
        await (async () => await listener([]))().catch((e) => {
          this.logger.Error().Err(e).Msg("subscriber error");
        });
      }
    }
  }
};
function toSortedArray(set) {
  if (!set) return [];
  return Object.entries(set).sort(([a], [b]) => a.localeCompare(b)).map(([k, v]) => ({ [k]: v }));
}
function fireproof(name, opts) {
  const key = JSON.stringify(
    toSortedArray({
      name,
      stores: toSortedArray(opts?.store?.stores)
    })
  );
  let db = Database.databases.get(key);
  if (!db) {
    db = new Database(name, opts);
    Database.databases.set(key, db);
  }
  return db;
}
function makeName(fnString) {
  const regex = /\(([^,()]+,\s*[^,()]+|\[[^\]]+\],\s*[^,()]+)\)/g;
  let found = null;
  const matches = Array.from(fnString.matchAll(regex), (match) => match[1].trim());
  if (matches.length === 0) {
    found = /=>\s*{?\s*([^{}]+)\s*}?/.exec(fnString);
    if (found && found[1].includes("return")) {
      found = null;
    }
  }
  if (!found) {
    return fnString;
  } else {
    return found[1];
  }
}

// src/runtime/index.ts
var runtime_exports = {};
__export(runtime_exports, {
  FILESTORE_VERSION: () => FILESTORE_VERSION,
  INDEXDB_VERSION: () => INDEXDB_VERSION,
  files: () => files_exports,
  getFileName: () => getFileName,
  getPath: () => getPath,
  kb: () => key_bag_exports,
  kc: () => keyed_crypto_exports,
  mf: () => wait_pr_multiformats_exports,
  runtimeFn: () => runtimeFn4
});

// src/runtime/gateways/file/node/utils.ts
import { getStore as getStore2 } from "@fireproof/core";
function getPath(url, sthis) {
  const basePath = url.pathname;
  const name = url.getParam("name");
  if (name) {
    const version = url.getParam("version");
    if (!version) throw sthis.logger.Error().Url(url).Msg(`version not found`).AsError();
    return sthis.pathOps.join(basePath, version, name);
  }
  return sthis.pathOps.join(basePath);
}
function getFileName(url, sthis) {
  const key = url.getParam("key");
  if (!key) throw sthis.logger.Error().Url(url).Msg(`key not found`).AsError();
  const res = getStore2(url, sthis, (...a) => a.join("-"));
  switch (res.store) {
    case "data":
      return sthis.pathOps.join(res.name, key + ".car");
    case "wal":
    case "meta":
      return sthis.pathOps.join(res.name, key + ".json");
    default:
      throw sthis.logger.Error().Url(url).Msg(`unsupported store type`).AsError();
  }
}

// src/runtime/wait-pr-multiformats/index.ts
var wait_pr_multiformats_exports = {};
__export(wait_pr_multiformats_exports, {
  block: () => block_exports,
  codec: () => codec_interface_exports
});

// src/runtime/wait-pr-multiformats/codec-interface.ts
var codec_interface_exports = {};

// src/runtime/index.ts
import { runtimeFn as runtimeFn4 } from "@adviser/cement";

// src/runtime/gateways/file/version.ts
var FILESTORE_VERSION = "v0.19-file";

// src/runtime/gateways/indexdb/version.ts
var INDEXDB_VERSION = "v0.19-indexdb";

// src/version.ts
var PACKAGE_VERSION = Object.keys({
  "0.19.125": "xxxx"
})[0];
export {
  CRDT,
  Database,
  Index,
  NotFoundError,
  PACKAGE_VERSION,
  Result,
  UInt8ArrayEqual,
  blockstore_exports as blockstore,
  blockstore_exports as bs,
  dataDir,
  ensureLogger,
  ensureSuperLog,
  ensureSuperThis,
  exceptionWrapper,
  falsyToUndef,
  fireproof,
  getKey,
  getName,
  getStore,
  index,
  isFalsy,
  isNotFoundError,
  onSuperThis,
  runtime_exports as rt,
  runtime_exports as runtime,
  throwFalsy
};
//# sourceMappingURL=index.js.map